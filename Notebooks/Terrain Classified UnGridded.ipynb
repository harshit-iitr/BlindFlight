{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 125981,
          "databundleVersionId": 14910697,
          "sourceType": "competition"
        },
        {
          "sourceId": 14214076,
          "sourceType": "datasetVersion",
          "datasetId": 9066772
        },
        {
          "sourceId": 691427,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 524219,
          "modelId": 538233
        },
        {
          "sourceId": 691428,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 524220,
          "modelId": 538234
        },
        {
          "sourceId": 691429,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 524221,
          "modelId": 538235
        },
        {
          "sourceId": 691430,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 524222,
          "modelId": 538236
        },
        {
          "sourceId": 691432,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 524224,
          "modelId": 538238
        }
      ],
      "dockerImageVersionId": 31236,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "notebookbfc9768916",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "7gju3brAqyQg"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "the_blind_flight_synapse_drive_ps_1_path = kagglehub.competition_download('the-blind-flight-synapse-drive-ps-1')\n",
        "championsproo_subfill4_path = kagglehub.dataset_download('championsproo/subfill4')\n",
        "championsproo_blindflightdesert_pytorch_default_1_path = kagglehub.model_download('championsproo/blindflightdesert/PyTorch/default/1')\n",
        "championsproo_blindflightterrain_pytorch_default_1_path = kagglehub.model_download('championsproo/blindflightterrain/PyTorch/default/1')\n",
        "championsproo_blindflightforest_pytorch_default_1_path = kagglehub.model_download('championsproo/blindflightforest/PyTorch/default/1')\n",
        "championsproo_blindflightlab_pytorch_default_1_path = kagglehub.model_download('championsproo/blindflightlab/PyTorch/default/1')\n",
        "championsproo_blindflightskewst_pytorch_default_1_path = kagglehub.model_download('championsproo/blindflightskewst/PyTorch/default/1')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "1H-oJxQsqyQh"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y numpy opencv-python opencv-python-headless pandas albumentations segmentation-models-pytorch timm\n",
        "!pip install \\\n",
        "    numpy==1.26.4 \\\n",
        "    opencv-python-headless \\\n",
        "    pandas \\\n",
        "    albumentations \\\n",
        "    timm \\\n",
        "    segmentation-models-pytorch==0.3.3 \\\n",
        "    --quiet\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "9g9_0-wBqyQi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random, numpy as np, cv2, torch, torch.nn as nn, torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from PIL import Image, ImageDraw\n",
        "import segmentation_models_pytorch as smp\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ---------------- CONFIGURATION ----------------\n",
        "# CHANGE THIS ID TO TRAIN DIFFERENT SPECIALISTS!\n",
        "# 1 = Forest Specialist\n",
        "# 2 = Desert Specialist\n",
        "TARGET_TERRAIN_ID = 2\n",
        "MODEL_NAME = \"unet_forest_specialist.pth\" if TARGET_TERRAIN_ID == 1 else \"unet_desert_specialist.pth\"\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "GRID_SIZE = 20\n",
        "TILE_SIZE = 40\n",
        "IMG_SIZE = 800\n",
        "BATCH_SIZE = 32\n",
        "ACCUM_STEPS = 4\n",
        "\n",
        "# ---------------- ASSETS (Same as before) ----------------\n",
        "INPUT_ROOT = Path(\"/kaggle/input/the-blind-flight-synapse-drive-ps-1/SynapseDrive_Dataset\")\n",
        "ASSET_ROOT = next((p for p in INPUT_ROOT.rglob(\"assets\") if p.is_dir()), Path(\"assets\"))\n",
        "\n",
        "def load_asset(path):\n",
        "    try: return Image.open(path).convert(\"RGBA\").resize((TILE_SIZE, TILE_SIZE))\n",
        "    except: return Image.new(\"RGBA\", (TILE_SIZE, TILE_SIZE), (128,128,128,255))\n",
        "\n",
        "# We only strictly need the assets for the target ID, but loading all is safer for code compat\n",
        "ASSETS = {\n",
        "    0: {\"floor\":[load_asset(ASSET_ROOT/\"lab/t2_floor.png\")], \"wall\":[load_asset(ASSET_ROOT/\"lab/t2_wall.png\")], \"hazard\":[load_asset(ASSET_ROOT/\"lab/t2_glue.png\")], \"start\":load_asset(ASSET_ROOT/\"lab/t2_drone.png\"), \"goal\":load_asset(ASSET_ROOT/\"lab/t2_goal.png\")},\n",
        "    1: {\"floor\":[load_asset(ASSET_ROOT/\"forest/t0_dirt.png\")], \"wall\":[load_asset(ASSET_ROOT/\"forest/t0_tree.png\")], \"hazard\":[load_asset(ASSET_ROOT/\"forest/t0_puddle.png\")], \"start\":load_asset(ASSET_ROOT/\"forest/t0_startship.png\"), \"goal\":load_asset(ASSET_ROOT/\"forest/t0_goal.png\")},\n",
        "    2: {\"floor\":[load_asset(ASSET_ROOT/\"desert/t1_sand.png\")], \"wall\":[load_asset(ASSET_ROOT/\"desert/t1_rocks.png\")], \"hazard\":[load_asset(ASSET_ROOT/\"desert/t1_quicksand.png\")], \"start\":load_asset(ASSET_ROOT/\"desert/t1_rover.png\"), \"goal\":load_asset(ASSET_ROOT/\"desert/t1_goal.png\")}\n",
        "}\n",
        "\n",
        "# ---------------- SPECIALIST DATASET ----------------\n",
        "class SpecialistDataset(Dataset):\n",
        "    def __init__(self, length=10000, target_id=1):\n",
        "        self.length = length\n",
        "        self.target_id = target_id # FORCES this terrain only\n",
        "        self.color = A.Compose([\n",
        "            A.HueSaturationValue(5, 10, 5, p=0.4),\n",
        "            A.RGBShift(10, 10, 10, p=0.3),\n",
        "            A.RandomBrightnessContrast(0.1, 0.1, p=0.4),\n",
        "        ])\n",
        "        self.blur = A.OneOf([A.GaussianBlur((3, 5), p=1.0), A.MotionBlur((3, 7), p=1.0)], p=0.4)\n",
        "        self.final = A.Compose([A.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)), ToTensorV2()])\n",
        "\n",
        "    def __len__(self): return self.length\n",
        "\n",
        "    def mild_skew(self, img, mask):\n",
        "        if random.random() > 0.4: return img, mask\n",
        "        h, w = img.shape[:2]\n",
        "        limit = 40\n",
        "        pts1 = np.float32([[0, 0], [w, 0], [0, h], [w, h]])\n",
        "        pts2 = np.float32([\n",
        "            [random.randint(0, limit), random.randint(0, limit)],\n",
        "            [w - random.randint(0, limit), random.randint(0, limit)],\n",
        "            [random.randint(0, limit), h - random.randint(0, limit)],\n",
        "            [w - random.randint(0, limit), h - random.randint(0, limit)]\n",
        "        ])\n",
        "        M = cv2.getPerspectiveTransform(pts1, pts2)\n",
        "        img = cv2.warpPerspective(img, M, (w, h), borderMode=cv2.BORDER_REFLECT_101)\n",
        "        mask = cv2.warpPerspective(mask, M, (w, h), flags=cv2.INTER_NEAREST, borderMode=cv2.BORDER_REFLECT_101)\n",
        "        return img, mask\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # --- SPECIALIST LOGIC: ONLY GENERATE TARGET TERRAIN ---\n",
        "        t_id = self.target_id\n",
        "        assets = ASSETS[t_id]\n",
        "\n",
        "        grid = np.random.choice([0, 1, 2], (GRID_SIZE, GRID_SIZE), p=[0.7, 0.2, 0.1])\n",
        "        s, g = random.sample([(r, c) for r in range(GRID_SIZE) for c in range(GRID_SIZE)], 2)\n",
        "        grid[s] = 3; grid[g] = 4\n",
        "        k = random.choice([0, 1, 2, 3])\n",
        "        if k > 0: grid = np.rot90(grid, k=k)\n",
        "\n",
        "        canvas = Image.new(\"RGBA\", (IMG_SIZE, IMG_SIZE), (0, 0, 0, 255))\n",
        "        draw = ImageDraw.Draw(canvas)\n",
        "\n",
        "        for r in range(GRID_SIZE):\n",
        "            for c in range(GRID_SIZE):\n",
        "                x, y = c * TILE_SIZE, r * TILE_SIZE\n",
        "                canvas.paste(random.choice(assets[\"floor\"]), (x, y))\n",
        "                cell = grid[r, c]\n",
        "                if cell == 1: canvas.paste(random.choice(assets[\"wall\"]), (x, y))\n",
        "                elif cell == 2: canvas.paste(random.choice(assets[\"hazard\"]), (x, y))\n",
        "                elif cell == 3: canvas.paste(assets[\"start\"], (x, y))\n",
        "                elif cell == 4: canvas.paste(assets[\"goal\"], (x, y))\n",
        "                draw.rectangle([x, y, x + TILE_SIZE - 1, y + TILE_SIZE - 1], outline=(0, 0, 0), width=2)\n",
        "\n",
        "        img = np.array(canvas.convert(\"RGB\"))\n",
        "        mask_full = cv2.resize(grid.astype(np.uint8), (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)\n",
        "        img, mask_full = self.mild_skew(img, mask_full)\n",
        "\n",
        "        img = self.color(image=img)[\"image\"]\n",
        "        img = self.blur(image=img)[\"image\"]\n",
        "        img = self.final(image=img)[\"image\"]\n",
        "\n",
        "        mask = cv2.resize(mask_full, (GRID_SIZE, GRID_SIZE), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        # We don't need to return t_id because we know what it is,\n",
        "        # but keeping format consistent with your pipelines\n",
        "        return img, torch.from_numpy(mask).long()\n",
        "\n",
        "# ---------------- MODEL (Standard UNet) ----------------\n",
        "# Specialists don't need the terrain head, just the segmentation head\n",
        "class SpecialistUNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.unet = smp.Unet(encoder_name=\"resnet34\", encoder_weights=\"imagenet\", in_channels=3, classes=5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Direct segmentation, no terrain auxiliary output\n",
        "        return self.unet(x)\n",
        "\n",
        "# ---------------- TRAIN ----------------\n",
        "def train_specialist():\n",
        "    # Load Specialist Dataset\n",
        "    ds = SpecialistDataset(length=10000, target_id=TARGET_TERRAIN_ID)\n",
        "    dl = DataLoader(ds, BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
        "\n",
        "    model = SpecialistUNet().to(DEVICE)\n",
        "    if torch.cuda.device_count() > 1: model = nn.DataParallel(model)\n",
        "\n",
        "    opt = optim.AdamW(model.parameters(), 1e-3, weight_decay=1e-2)\n",
        "    scaler = GradScaler()\n",
        "    sched = optim.lr_scheduler.ReduceLROnPlateau(opt, \"min\", 0.5, 2)\n",
        "\n",
        "    # Loss for segmentation only\n",
        "    ce = nn.CrossEntropyLoss(weight=torch.tensor([1.0, 5.0, 5.0, 50.0, 50.0], device=DEVICE))\n",
        "\n",
        "    print(f\"ðŸš€ Starting Specialist Training for ID {TARGET_TERRAIN_ID}...\")\n",
        "    print(f\"ðŸ’¾ Saving to: {MODEL_NAME}\")\n",
        "\n",
        "    for ep in range(12): # 12 Epochs is usually enough for specialized tasks\n",
        "        model.train()\n",
        "        loop = tqdm(dl, desc=f\"Epoch {ep+1}/12\")\n",
        "        epoch_loss = 0\n",
        "\n",
        "        for i, (x, y) in enumerate(loop):\n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "\n",
        "            with autocast():\n",
        "                # Note: Model output is raw logits here because we removed interpolation in model class\n",
        "                # We interpolate logits to match label size\n",
        "                logits = model(x)\n",
        "                logits = torch.nn.functional.interpolate(logits, (GRID_SIZE, GRID_SIZE), mode='bilinear', align_corners=False)\n",
        "\n",
        "                loss = ce(logits, y) / ACCUM_STEPS\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            if (i+1) % ACCUM_STEPS == 0:\n",
        "                scaler.step(opt); scaler.update(); opt.zero_grad()\n",
        "                epoch_loss += loss.item() * ACCUM_STEPS\n",
        "                loop.set_postfix({\"Loss\": f\"{loss.item()*ACCUM_STEPS:.4f}\"})\n",
        "\n",
        "        sched.step(epoch_loss/len(dl))\n",
        "\n",
        "    torch.save(model.module.state_dict() if isinstance(model, nn.DataParallel) else model.state_dict(), MODEL_NAME)\n",
        "    print(f\"âœ… {MODEL_NAME} Saved Successfully!\")\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    train_specialist()"
      ],
      "metadata": {
        "trusted": true,
        "id": "ixD3isToqyQj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- TERRAIN CLASSIFIER CONFIG ----------------\n",
        "CLASSIFIER_MODEL_NAME = \"terrain_classifier.pth\"\n",
        "\n",
        "# ---------------- CLASSIFIER DATASET (Randomized) ----------------\n",
        "# This dataset MUST generate all 3 terrains to teach the classifier the difference\n",
        "class ClassifierDataset(Dataset):\n",
        "    def __init__(self, length=10000):\n",
        "        self.length = length\n",
        "        self.specialist_ds = SpecialistDataset(length=1) # Helper to reuse logic\n",
        "\n",
        "    def __len__(self): return self.length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Randomly pick a terrain\n",
        "        t_id = random.choice([0, 1, 2])\n",
        "\n",
        "        # Temporarily switch the helper's target_id\n",
        "        self.specialist_ds.target_id = t_id\n",
        "\n",
        "        # Get image (we ignore the mask, we only need the label t_id)\n",
        "        img, _ = self.specialist_ds.__getitem__(0)\n",
        "\n",
        "        return img, torch.tensor(t_id).long()\n",
        "\n",
        "# ---------------- CLASSIFIER MODEL ----------------\n",
        "class TerrainRouter(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Load a pretrained ResNet, remove the FC layer, add our own\n",
        "        self.backbone = smp.encoders.get_encoder(\"resnet34\", in_channels=3, weights=\"imagenet\")\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 3) # 3 Classes: Lab, Forest, Desert\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        feats = self.backbone(x)\n",
        "        # ResNet34 features are a list, last one is the deepest (512 channels)\n",
        "        x = feats[-1]\n",
        "        x = self.pool(x)\n",
        "        return self.head(x)\n",
        "\n",
        "# ---------------- TRAIN ROUTER ----------------\n",
        "def train_router():\n",
        "    dl = DataLoader(ClassifierDataset(), BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
        "    model = TerrainRouter().to(DEVICE)\n",
        "\n",
        "    opt = optim.Adam(model.parameters(), lr=1e-4)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    print(f\"ðŸš€ Starting Terrain Router Training...\")\n",
        "\n",
        "    for ep in range(5): # Classifiers learn very fast, 5 epochs is plenty\n",
        "        model.train()\n",
        "        loop = tqdm(dl, desc=f\"Router Epoch {ep+1}/5\")\n",
        "\n",
        "        for x, t in loop:\n",
        "            x, t = x.to(DEVICE), t.to(DEVICE)\n",
        "\n",
        "            opt.zero_grad()\n",
        "            logits = model(x)\n",
        "            loss = loss_fn(logits, t)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            loop.set_postfix({\"Acc\": f\"{(logits.argmax(1) == t).float().mean():.2f}\", \"Loss\": f\"{loss.item():.4f}\"})\n",
        "\n",
        "    torch.save(model.state_dict(), CLASSIFIER_MODEL_NAME)\n",
        "    print(f\"âœ… {CLASSIFIER_MODEL_NAME} Saved!\")\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    train_router()"
      ],
      "metadata": {
        "trusted": true,
        "id": "7seWbTg5qyQk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random, numpy as np, cv2, torch, torch.nn as nn, torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from PIL import Image, ImageDraw\n",
        "import segmentation_models_pytorch as smp\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ---------------- CONFIGURATION ----------------\n",
        "# CHANGE THIS ID TO TRAIN DIFFERENT SPECIALISTS!\n",
        "# 1 = Forest Specialist\n",
        "# 2 = Desert Specialist\n",
        "TARGET_TERRAIN_ID = 1\n",
        "MODEL_NAME = \"unet_forest_specialist.pth\" if TARGET_TERRAIN_ID == 1 else \"unet_desert_specialist.pth\"\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "GRID_SIZE = 20\n",
        "TILE_SIZE = 40\n",
        "IMG_SIZE = 800\n",
        "BATCH_SIZE = 32\n",
        "ACCUM_STEPS = 4\n",
        "\n",
        "# ---------------- ASSETS (Same as before) ----------------\n",
        "INPUT_ROOT = Path(\"/kaggle/input/the-blind-flight-synapse-drive-ps-1/SynapseDrive_Dataset\")\n",
        "ASSET_ROOT = next((p for p in INPUT_ROOT.rglob(\"assets\") if p.is_dir()), Path(\"assets\"))\n",
        "\n",
        "def load_asset(path):\n",
        "    try: return Image.open(path).convert(\"RGBA\").resize((TILE_SIZE, TILE_SIZE))\n",
        "    except: return Image.new(\"RGBA\", (TILE_SIZE, TILE_SIZE), (128,128,128,255))\n",
        "\n",
        "# We only strictly need the assets for the target ID, but loading all is safer for code compat\n",
        "ASSETS = {\n",
        "    0: {\"floor\":[load_asset(ASSET_ROOT/\"lab/t2_floor.png\")], \"wall\":[load_asset(ASSET_ROOT/\"lab/t2_wall.png\")], \"hazard\":[load_asset(ASSET_ROOT/\"lab/t2_glue.png\")], \"start\":load_asset(ASSET_ROOT/\"lab/t2_drone.png\"), \"goal\":load_asset(ASSET_ROOT/\"lab/t2_goal.png\")},\n",
        "    1: {\"floor\":[load_asset(ASSET_ROOT/\"forest/t0_dirt.png\")], \"wall\":[load_asset(ASSET_ROOT/\"forest/t0_tree.png\")], \"hazard\":[load_asset(ASSET_ROOT/\"forest/t0_puddle.png\")], \"start\":load_asset(ASSET_ROOT/\"forest/t0_startship.png\"), \"goal\":load_asset(ASSET_ROOT/\"forest/t0_goal.png\")},\n",
        "    2: {\"floor\":[load_asset(ASSET_ROOT/\"desert/t1_sand.png\")], \"wall\":[load_asset(ASSET_ROOT/\"desert/t1_rocks.png\")], \"hazard\":[load_asset(ASSET_ROOT/\"desert/t1_quicksand.png\")], \"start\":load_asset(ASSET_ROOT/\"desert/t1_rover.png\"), \"goal\":load_asset(ASSET_ROOT/\"desert/t1_goal.png\")}\n",
        "}\n",
        "\n",
        "# ---------------- SPECIALIST DATASET ----------------\n",
        "class SpecialistDataset(Dataset):\n",
        "    def __init__(self, length=10000, target_id=1):\n",
        "        self.length = length\n",
        "        self.target_id = target_id # FORCES this terrain only\n",
        "        self.color = A.Compose([\n",
        "            A.HueSaturationValue(5, 10, 5, p=0.4),\n",
        "            A.RGBShift(10, 10, 10, p=0.3),\n",
        "            A.RandomBrightnessContrast(0.1, 0.1, p=0.4),\n",
        "        ])\n",
        "        self.blur = A.OneOf([A.GaussianBlur((3, 5), p=1.0), A.MotionBlur((3, 7), p=1.0)], p=0.4)\n",
        "        self.final = A.Compose([A.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)), ToTensorV2()])\n",
        "\n",
        "    def __len__(self): return self.length\n",
        "\n",
        "    def mild_skew(self, img, mask):\n",
        "        if random.random() > 0.4: return img, mask\n",
        "        h, w = img.shape[:2]\n",
        "        limit = 40\n",
        "        pts1 = np.float32([[0, 0], [w, 0], [0, h], [w, h]])\n",
        "        pts2 = np.float32([\n",
        "            [random.randint(0, limit), random.randint(0, limit)],\n",
        "            [w - random.randint(0, limit), random.randint(0, limit)],\n",
        "            [random.randint(0, limit), h - random.randint(0, limit)],\n",
        "            [w - random.randint(0, limit), h - random.randint(0, limit)]\n",
        "        ])\n",
        "        M = cv2.getPerspectiveTransform(pts1, pts2)\n",
        "        img = cv2.warpPerspective(img, M, (w, h), borderMode=cv2.BORDER_REFLECT_101)\n",
        "        mask = cv2.warpPerspective(mask, M, (w, h), flags=cv2.INTER_NEAREST, borderMode=cv2.BORDER_REFLECT_101)\n",
        "        return img, mask\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # --- SPECIALIST LOGIC: ONLY GENERATE TARGET TERRAIN ---\n",
        "        t_id = self.target_id\n",
        "        assets = ASSETS[t_id]\n",
        "\n",
        "        grid = np.random.choice([0, 1, 2], (GRID_SIZE, GRID_SIZE), p=[0.7, 0.2, 0.1])\n",
        "        s, g = random.sample([(r, c) for r in range(GRID_SIZE) for c in range(GRID_SIZE)], 2)\n",
        "        grid[s] = 3; grid[g] = 4\n",
        "        k = random.choice([0, 1, 2, 3])\n",
        "        if k > 0: grid = np.rot90(grid, k=k)\n",
        "\n",
        "        canvas = Image.new(\"RGBA\", (IMG_SIZE, IMG_SIZE), (0, 0, 0, 255))\n",
        "        draw = ImageDraw.Draw(canvas)\n",
        "\n",
        "        for r in range(GRID_SIZE):\n",
        "            for c in range(GRID_SIZE):\n",
        "                x, y = c * TILE_SIZE, r * TILE_SIZE\n",
        "                canvas.paste(random.choice(assets[\"floor\"]), (x, y))\n",
        "                cell = grid[r, c]\n",
        "                if cell == 1: canvas.paste(random.choice(assets[\"wall\"]), (x, y))\n",
        "                elif cell == 2: canvas.paste(random.choice(assets[\"hazard\"]), (x, y))\n",
        "                elif cell == 3: canvas.paste(assets[\"start\"], (x, y))\n",
        "                elif cell == 4: canvas.paste(assets[\"goal\"], (x, y))\n",
        "                draw.rectangle([x, y, x + TILE_SIZE - 1, y + TILE_SIZE - 1], outline=(0, 0, 0), width=2)\n",
        "\n",
        "        img = np.array(canvas.convert(\"RGB\"))\n",
        "        mask_full = cv2.resize(grid.astype(np.uint8), (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)\n",
        "        img, mask_full = self.mild_skew(img, mask_full)\n",
        "\n",
        "        img = self.color(image=img)[\"image\"]\n",
        "        img = self.blur(image=img)[\"image\"]\n",
        "        img = self.final(image=img)[\"image\"]\n",
        "\n",
        "        mask = cv2.resize(mask_full, (GRID_SIZE, GRID_SIZE), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        # We don't need to return t_id because we know what it is,\n",
        "        # but keeping format consistent with your pipelines\n",
        "        return img, torch.from_numpy(mask).long()\n",
        "\n",
        "# ---------------- MODEL (Standard UNet) ----------------\n",
        "# Specialists don't need the terrain head, just the segmentation head\n",
        "class SpecialistUNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.unet = smp.Unet(encoder_name=\"resnet34\", encoder_weights=\"imagenet\", in_channels=3, classes=5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Direct segmentation, no terrain auxiliary output\n",
        "        return self.unet(x)\n",
        "\n",
        "# ---------------- TRAIN ----------------\n",
        "def train_specialist():\n",
        "    # Load Specialist Dataset\n",
        "    ds = SpecialistDataset(length=10000, target_id=TARGET_TERRAIN_ID)\n",
        "    dl = DataLoader(ds, BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
        "\n",
        "    model = SpecialistUNet().to(DEVICE)\n",
        "    if torch.cuda.device_count() > 1: model = nn.DataParallel(model)\n",
        "\n",
        "    opt = optim.AdamW(model.parameters(), 1e-3, weight_decay=1e-2)\n",
        "    scaler = GradScaler()\n",
        "    sched = optim.lr_scheduler.ReduceLROnPlateau(opt, \"min\", 0.5, 2)\n",
        "\n",
        "    # Loss for segmentation only\n",
        "    ce = nn.CrossEntropyLoss(weight=torch.tensor([1.0, 5.0, 5.0, 50.0, 50.0], device=DEVICE))\n",
        "\n",
        "    print(f\"ðŸš€ Starting Specialist Training for ID {TARGET_TERRAIN_ID}...\")\n",
        "    print(f\"ðŸ’¾ Saving to: {MODEL_NAME}\")\n",
        "\n",
        "    for ep in range(12): # 12 Epochs is usually enough for specialized tasks\n",
        "        model.train()\n",
        "        loop = tqdm(dl, desc=f\"Epoch {ep+1}/12\")\n",
        "        epoch_loss = 0\n",
        "\n",
        "        for i, (x, y) in enumerate(loop):\n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "\n",
        "            with autocast():\n",
        "                # Note: Model output is raw logits here because we removed interpolation in model class\n",
        "                # We interpolate logits to match label size\n",
        "                logits = model(x)\n",
        "                logits = torch.nn.functional.interpolate(logits, (GRID_SIZE, GRID_SIZE), mode='bilinear', align_corners=False)\n",
        "\n",
        "                loss = ce(logits, y) / ACCUM_STEPS\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            if (i+1) % ACCUM_STEPS == 0:\n",
        "                scaler.step(opt); scaler.update(); opt.zero_grad()\n",
        "                epoch_loss += loss.item() * ACCUM_STEPS\n",
        "                loop.set_postfix({\"Loss\": f\"{loss.item()*ACCUM_STEPS:.4f}\"})\n",
        "\n",
        "        sched.step(epoch_loss/len(dl))\n",
        "\n",
        "    torch.save(model.module.state_dict() if isinstance(model, nn.DataParallel) else model.state_dict(), MODEL_NAME)\n",
        "    print(f\"âœ… {MODEL_NAME} Saved Successfully!\")\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    train_specialist()"
      ],
      "metadata": {
        "trusted": true,
        "id": "MOL0Fj5qqyQk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import json\n",
        "import heapq\n",
        "import random\n",
        "import segmentation_models_pytorch as smp\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# FILES\n",
        "LAB_PATH     = \"/kaggle/input/blindflightlab/pytorch/default/1/lab_specialist_final.pth\"\n",
        "FOREST_PATH  = \"/kaggle/input/blindflightforest/pytorch/default/1/unet_forest_specialist.pth\"\n",
        "DESERT_PATH  = \"/kaggle/input/blindflightdesert/pytorch/default/1/unet_desert_specialist.pth\"\n",
        "ROUTER_PATH  = \"/kaggle/input/blindflightterrain/pytorch/default/1/terrain_classifier.pth\"\n",
        "\n",
        "TEST_IMG_DIR = Path(\"/kaggle/input/the-blind-flight-synapse-drive-ps-1/SynapseDrive_Dataset/test/images\")\n",
        "TEST_VEL_DIR = Path(\"/kaggle/input/the-blind-flight-synapse-drive-ps-1/SynapseDrive_Dataset/test/velocities\")\n",
        "\n",
        "# --- MODEL CLASSES ---\n",
        "class MultiHeadUNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.unet = smp.Unet(encoder_name=\"resnet34\", encoder_weights=None, in_channels=3, classes=5)\n",
        "        c = self.unet.encoder.out_channels[-1]\n",
        "        self.terrain = nn.Sequential(nn.AdaptiveAvgPool2d(1), nn.Flatten(), nn.Linear(c, 64), nn.ReLU(), nn.Linear(64, 3))\n",
        "    def forward(self, x): return self.unet(x), self.terrain(self.unet.encoder(x)[-1])\n",
        "\n",
        "class SpecialistUNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.unet = smp.Unet(encoder_name=\"resnet34\", encoder_weights=None, in_channels=3, classes=5)\n",
        "    def forward(self, x): return self.unet(x)\n",
        "\n",
        "class TerrainRouter(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.backbone = smp.encoders.get_encoder(\"resnet34\", in_channels=3, weights=None)\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.head = nn.Sequential(nn.Flatten(), nn.Linear(512, 128), nn.ReLU(), nn.Dropout(0.2), nn.Linear(128, 3))\n",
        "    def forward(self, x): return self.head(self.pool(self.backbone(x)[-1]))\n",
        "\n",
        "def load_weights_smart(model, path):\n",
        "    if not Path(path).exists(): return False\n",
        "    state = torch.load(path, map_location=\"cpu\")\n",
        "    if list(state.keys())[0].startswith('module.'): state = {k[7:]: v for k, v in state.items()}\n",
        "    model_keys = list(model.state_dict().keys())\n",
        "    file_keys = list(state.keys())\n",
        "    if model_keys[0].startswith('unet.') and not file_keys[0].startswith('unet.'):\n",
        "        state = {f\"unet.{k}\": v for k, v in state.items()}\n",
        "    elif not model_keys[0].startswith('unet.') and file_keys[0].startswith('unet.'):\n",
        "        state = {k[5:]: v for k, v in state.items() if k.startswith('unet.')}\n",
        "    try: model.load_state_dict(state, strict=False); return True\n",
        "    except: return False\n",
        "\n",
        "# --- PATHFINDER (Probability Based) ---\n",
        "def solve_path(grid, probs, boost, t_id):\n",
        "    costs = {\n",
        "        0: {0: 1.0, 1: float('inf'), 2: 3.0, 3: 1.0, 4: 2.0},\n",
        "        1: {0: 1.5, 1: float('inf'), 2: 2.8, 3: 1.5, 4: 2.5},\n",
        "        2: {0: 1.2, 1: float('inf'), 2: 3.7, 3: 1.2, 4: 2.2}\n",
        "    }[t_id]\n",
        "\n",
        "    starts, goals = np.argwhere(grid == 3), np.argwhere(grid == 4)\n",
        "    if len(starts) == 0 or len(goals) == 0: return \"NO PATH\", []\n",
        "\n",
        "    start = tuple(max(starts, key=lambda p: probs[3, p[0], p[1]]))\n",
        "    goal = tuple(max(goals, key=lambda p: probs[4, p[0], p[1]]))\n",
        "\n",
        "    pq = [(0, 0, start)]\n",
        "    g_score = {start: 0.0}\n",
        "    came_from = {start: None}\n",
        "\n",
        "    while pq:\n",
        "        _, curr_g, curr = heapq.heappop(pq)\n",
        "        if curr_g > g_score.get(curr, float('inf')): continue\n",
        "        if curr == goal: break\n",
        "\n",
        "        r, c = curr\n",
        "        for next_node, move in [((r-1,c),'u'),((r+1,c),'d'),((r,c-1),'l'),((r,c+1),'r')]:\n",
        "            nr, nc = next_node\n",
        "            if 0 <= nr < 20 and 0 <= nc < 20 and grid[nr, nc] != 1:\n",
        "                step_cost = max(costs.get(grid[nr,nc], 1.0) - boost[nr,nc], 0.01)\n",
        "                new_g = curr_g + step_cost\n",
        "                if new_g < g_score.get(next_node, float('inf')):\n",
        "                    g_score[next_node] = new_g\n",
        "                    came_from[next_node] = (curr, move)\n",
        "                    h = abs(nr - goal[0]) + abs(nc - goal[1])\n",
        "                    heapq.heappush(pq, (new_g + h, new_g, next_node))\n",
        "\n",
        "    if goal not in came_from: return \"NO PATH\", []\n",
        "    path_str, coords, curr = [], [], goal\n",
        "    while curr != start:\n",
        "        prev, move = came_from[curr]\n",
        "        path_str.append(move)\n",
        "        coords.append(curr)\n",
        "        curr = prev\n",
        "    coords.append(start)\n",
        "    return \"\".join(path_str[::-1]), coords[::-1]\n",
        "\n",
        "# --- VISUALIZER ---\n",
        "def visualize_ensemble(num_samples=5):\n",
        "    models = {\n",
        "        'router': TerrainRouter().to(DEVICE),\n",
        "        0: MultiHeadUNet().to(DEVICE), 1: SpecialistUNet().to(DEVICE), 2: SpecialistUNet().to(DEVICE)\n",
        "    }\n",
        "    print(\"â³ Loading Models...\")\n",
        "    load_weights_smart(models['router'], ROUTER_PATH)\n",
        "    load_weights_smart(models[0], LAB_PATH)\n",
        "    load_weights_smart(models[1], FOREST_PATH)\n",
        "    load_weights_smart(models[2], DESERT_PATH)\n",
        "    for m in models.values(): m.eval()\n",
        "\n",
        "    transform = A.Compose([A.Resize(800, 800), A.Normalize(), ToTensorV2()])\n",
        "    files = list(TEST_IMG_DIR.glob(\"*.png\"))\n",
        "    samples = random.sample(files, min(len(files), num_samples))\n",
        "\n",
        "    for img_path in samples:\n",
        "        raw_img = np.array(Image.open(img_path).convert(\"RGB\"))\n",
        "        x = transform(image=raw_img)['image'].unsqueeze(0).to(DEVICE)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            router_out = models['router'](x)\n",
        "            t_id = torch.argmax(router_out, dim=1).item()\n",
        "            t_name = [\"LAB\", \"FOREST\", \"DESERT\"][t_id]\n",
        "            spec_out = models[t_id](x)\n",
        "            seg_logits = spec_out[0] if isinstance(spec_out, tuple) else spec_out\n",
        "            if seg_logits.shape[-1] != 20:\n",
        "                seg_logits = torch.nn.functional.interpolate(seg_logits, (20, 20), mode='bilinear', align_corners=False)\n",
        "\n",
        "            probs = torch.softmax(seg_logits, dim=1).squeeze().cpu().numpy()\n",
        "            grid = np.argmax(probs, axis=0)\n",
        "\n",
        "        boost = np.zeros((20, 20))\n",
        "        path_str, coords = solve_path(grid, probs, boost, t_id)\n",
        "\n",
        "        # --- PLOT ---\n",
        "        fig, ax = plt.subplots(1, 2, figsize=(16, 8))\n",
        "\n",
        "        # LEFT: Real Image\n",
        "        ax[0].imshow(raw_img)\n",
        "        ax[0].set_title(f\"Terrain: {t_name}\", fontsize=14)\n",
        "\n",
        "        # Calculate Coordinates (Precise Center of 40x40 tiles)\n",
        "        sy, sx = raw_img.shape[0]/20, raw_img.shape[1]/20\n",
        "\n",
        "        # Overlay a faint Grid to prove alignment logic\n",
        "        # Vertical lines\n",
        "        for i in range(1, 20):\n",
        "            ax[0].axvline(x=i*sx, color='white', linewidth=0.5, alpha=0.3)\n",
        "            ax[0].axhline(y=i*sy, color='white', linewidth=0.5, alpha=0.3)\n",
        "\n",
        "        if coords:\n",
        "            py, px = zip(*coords)\n",
        "            plot_px = [(c+0.5)*sx for c in px]\n",
        "            plot_py = [(r+0.5)*sy for r in py]\n",
        "\n",
        "            # Simple, Thin, Red Line\n",
        "            ax[0].plot(plot_px, plot_py, color='red', linewidth=2, label='Path')\n",
        "\n",
        "            # Standard Markers\n",
        "            ax[0].scatter(plot_px[0], plot_py[0], c='lime', s=80, edgecolors='black', label='Start', zorder=5)\n",
        "            ax[0].scatter(plot_px[-1], plot_py[-1], c='magenta', s=80, edgecolors='black', label='Goal', zorder=5)\n",
        "            ax[0].legend(loc='lower left')\n",
        "        else:\n",
        "            ax[0].text(400, 400, \"NO PATH FOUND\", c='red', fontsize=16, ha='center', backgroundcolor='black')\n",
        "\n",
        "        ax[0].axis('off')\n",
        "\n",
        "        # RIGHT: Logic View\n",
        "        cmap = plt.get_cmap('tab10', 5)\n",
        "        im = ax[1].imshow(grid, cmap=cmap, vmin=-0.5, vmax=4.5)\n",
        "        ax[1].set_title(\"Logic View (20x20)\", fontsize=14)\n",
        "\n",
        "        cbar = plt.colorbar(im, ax=ax[1], ticks=[0,1,2,3,4], fraction=0.046, pad=0.04)\n",
        "        cbar.ax.set_yticklabels(['Floor', 'Wall', 'Haz', 'Start', 'Goal'], fontsize=10)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    visualize_ensemble(15)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-18T15:16:21.124864Z",
          "iopub.execute_input": "2025-12-18T15:16:21.125488Z",
          "iopub.status.idle": "2025-12-18T15:16:37.48643Z",
          "shell.execute_reply.started": "2025-12-18T15:16:21.125458Z",
          "shell.execute_reply": "2025-12-18T15:16:37.485627Z"
        },
        "id": "2inYn2IrqyQl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import json\n",
        "import heapq\n",
        "import segmentation_models_pytorch as smp\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "USE_MULTI_GPU = torch.cuda.device_count() > 1\n",
        "\n",
        "# MODEL PATHS\n",
        "LAB_PATH     = \"/kaggle/input/blindflightlab/pytorch/default/1/lab_specialist_final.pth\"\n",
        "FOREST_PATH  = \"/kaggle/input/blindflightforest/pytorch/default/1/unet_forest_specialist.pth\"\n",
        "DESERT_PATH  = \"/kaggle/input/blindflightdesert/pytorch/default/1/unet_desert_specialist.pth\"\n",
        "ROUTER_PATH  = \"/kaggle/input/blindflightterrain/pytorch/default/1/terrain_classifier.pth\"\n",
        "\n",
        "# DATA PATHS\n",
        "TEST_IMG_DIR = Path(\"/kaggle/input/the-blind-flight-synapse-drive-ps-1/SynapseDrive_Dataset/test/images\")\n",
        "TEST_VEL_DIR = Path(\"/kaggle/input/the-blind-flight-synapse-drive-ps-1/SynapseDrive_Dataset/test/velocities\")\n",
        "OUTPUT_CSV = \"submission.csv\"\n",
        "\n",
        "# BATCH PROCESSING\n",
        "BATCH_SIZE = 8  # Process multiple images simultaneously\n",
        "\n",
        "# --- MODEL CLASSES ---\n",
        "class MultiHeadUNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.unet = smp.Unet(encoder_name=\"resnet34\", encoder_weights=None, in_channels=3, classes=5)\n",
        "        c = self.unet.encoder.out_channels[-1]\n",
        "        self.terrain = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1), nn.Flatten(),\n",
        "            nn.Linear(c, 64), nn.ReLU(), nn.Linear(64, 3)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.unet(x), self.terrain(self.unet.encoder(x)[-1])\n",
        "\n",
        "class SpecialistUNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.unet = smp.Unet(encoder_name=\"resnet34\", encoder_weights=None, in_channels=3, classes=5)\n",
        "    def forward(self, x):\n",
        "        return self.unet(x)\n",
        "\n",
        "class TerrainRouter(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.backbone = smp.encoders.get_encoder(\"resnet34\", in_channels=3, weights=None)\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Flatten(), nn.Linear(512, 128), nn.ReLU(),\n",
        "            nn.Dropout(0.2), nn.Linear(128, 3)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.head(self.pool(self.backbone(x)[-1]))\n",
        "\n",
        "def load_weights_smart(model, path):\n",
        "    \"\"\"Smart weight loader handling module prefixes\"\"\"\n",
        "    if not Path(path).exists():\n",
        "        print(f\"âš ï¸ Warning: {path} not found\")\n",
        "        return False\n",
        "\n",
        "    state = torch.load(path, map_location=\"cpu\")\n",
        "\n",
        "    # Remove 'module.' prefix if present (DataParallel)\n",
        "    if list(state.keys())[0].startswith('module.'):\n",
        "        state = {k[7:]: v for k, v in state.items()}\n",
        "\n",
        "    # Handle 'unet.' prefix mismatches\n",
        "    model_keys = list(model.state_dict().keys())\n",
        "    file_keys = list(state.keys())\n",
        "\n",
        "    if model_keys[0].startswith('unet.') and not file_keys[0].startswith('unet.'):\n",
        "        state = {f\"unet.{k}\": v for k, v in state.items()}\n",
        "    elif not model_keys[0].startswith('unet.') and file_keys[0].startswith('unet.'):\n",
        "        state = {k[5:]: v for k, v in state.items() if k.startswith('unet.')}\n",
        "\n",
        "    try:\n",
        "        model.load_state_dict(state, strict=False)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Error loading {path}: {e}\")\n",
        "        return False\n",
        "\n",
        "# --- A* PATHFINDER ---\n",
        "def solve_path(grid, probs, boost, t_id):\n",
        "    \"\"\"\n",
        "    A* pathfinding with velocity boost consideration\n",
        "    Returns: (path_string, coordinates_list)\n",
        "    \"\"\"\n",
        "    # Terrain-specific base costs\n",
        "    costs = {\n",
        "        0: {0: 1.0, 1: float('inf'), 2: 3.0, 3: 1.0, 4: 2.0},  # Lab\n",
        "        1: {0: 1.5, 1: float('inf'), 2: 2.8, 3: 1.5, 4: 2.5},  # Forest\n",
        "        2: {0: 1.2, 1: float('inf'), 2: 3.7, 3: 1.2, 4: 2.2}   # Desert\n",
        "    }[t_id]\n",
        "\n",
        "    # Find START and GOAL using probability-weighted selection\n",
        "    starts = np.argwhere(grid == 3)\n",
        "    goals = np.argwhere(grid == 4)\n",
        "\n",
        "    if len(starts) == 0 or len(goals) == 0:\n",
        "        return \"\", []\n",
        "\n",
        "    # Pick highest confidence START/GOAL\n",
        "    start = tuple(max(starts, key=lambda p: probs[3, p[0], p[1]]))\n",
        "    goal = tuple(max(goals, key=lambda p: probs[4, p[0], p[1]]))\n",
        "\n",
        "    # A* Search\n",
        "    pq = [(0, 0, start)]  # (f_score, g_score, node)\n",
        "    g_score = {start: 0.0}\n",
        "    came_from = {start: None}\n",
        "\n",
        "    while pq:\n",
        "        _, curr_g, curr = heapq.heappop(pq)\n",
        "\n",
        "        if curr_g > g_score.get(curr, float('inf')):\n",
        "            continue\n",
        "\n",
        "        if curr == goal:\n",
        "            break\n",
        "\n",
        "        r, c = curr\n",
        "        # Explore 4-connected neighbors\n",
        "        for next_node, move in [((r-1,c),'u'), ((r+1,c),'d'),\n",
        "                                 ((r,c-1),'l'), ((r,c+1),'r')]:\n",
        "            nr, nc = next_node\n",
        "\n",
        "            if 0 <= nr < 20 and 0 <= nc < 20 and grid[nr, nc] != 1:\n",
        "                # Calculate step cost with boost\n",
        "                base = costs.get(grid[nr, nc], 1.0)\n",
        "                step_cost = max(base - boost[nr, nc], 0.01)\n",
        "\n",
        "                new_g = curr_g + step_cost\n",
        "\n",
        "                if new_g < g_score.get(next_node, float('inf')):\n",
        "                    g_score[next_node] = new_g\n",
        "                    came_from[next_node] = (curr, move)\n",
        "\n",
        "                    # Manhattan heuristic\n",
        "                    h = abs(nr - goal[0]) + abs(nc - goal[1])\n",
        "                    heapq.heappush(pq, (new_g + h, new_g, next_node))\n",
        "\n",
        "    # Reconstruct path\n",
        "    if goal not in came_from:\n",
        "        return \"\", []\n",
        "\n",
        "    path_str = []\n",
        "    coords = []\n",
        "    curr = goal\n",
        "\n",
        "    while curr != start:\n",
        "        prev, move = came_from[curr]\n",
        "        path_str.append(move)\n",
        "        coords.append(curr)\n",
        "        curr = prev\n",
        "\n",
        "    coords.append(start)\n",
        "\n",
        "    return \"\".join(path_str[::-1]), coords[::-1]\n",
        "\n",
        "# --- BATCH DATASET ---\n",
        "class TestDataset(Dataset):\n",
        "    \"\"\"Dataset for batch processing test images\"\"\"\n",
        "    def __init__(self, img_paths, transform):\n",
        "        self.img_paths = img_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        image_id = img_path.stem\n",
        "        raw_img = np.array(Image.open(img_path).convert(\"RGB\"))\n",
        "        x = self.transform(image=raw_img)['image']\n",
        "\n",
        "        # Load velocity boost\n",
        "        vel_path = TEST_VEL_DIR / f\"{image_id}.json\"\n",
        "        boost = np.zeros((20, 20))\n",
        "\n",
        "        if vel_path.exists():\n",
        "            with open(vel_path, 'r') as f:\n",
        "                vel_data = json.load(f)\n",
        "                boost = np.array(vel_data['boost'])\n",
        "\n",
        "        return x, boost, image_id\n",
        "\n",
        "# --- MAIN SUBMISSION GENERATOR ---\n",
        "def generate_submission():\n",
        "    \"\"\"Generate submission.csv for all test images\"\"\"\n",
        "\n",
        "    print(\"ðŸš€ Blind Flight Submission Generator\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Load models\n",
        "    print(\"â³ Loading Models...\")\n",
        "    models = {\n",
        "        'router': TerrainRouter().to(DEVICE),\n",
        "        0: MultiHeadUNet().to(DEVICE),\n",
        "        1: SpecialistUNet().to(DEVICE),\n",
        "        2: SpecialistUNet().to(DEVICE)\n",
        "    }\n",
        "\n",
        "    load_weights_smart(models['router'], ROUTER_PATH)\n",
        "    load_weights_smart(models[0], LAB_PATH)\n",
        "    load_weights_smart(models[1], FOREST_PATH)\n",
        "    load_weights_smart(models[2], DESERT_PATH)\n",
        "\n",
        "    # Enable DataParallel for multi-GPU\n",
        "    if USE_MULTI_GPU:\n",
        "        print(f\"ðŸ”¥ Using {torch.cuda.device_count()} GPUs with DataParallel\")\n",
        "        models['router'] = nn.DataParallel(models['router'])\n",
        "        models[0] = nn.DataParallel(models[0])\n",
        "        models[1] = nn.DataParallel(models[1])\n",
        "        models[2] = nn.DataParallel(models[2])\n",
        "    else:\n",
        "        print(f\"ðŸ’» Using single GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "    for m in models.values():\n",
        "        m.eval()\n",
        "\n",
        "    print(\"âœ… Models Loaded Successfully\")\n",
        "\n",
        "    # Preprocessing\n",
        "    transform = A.Compose([\n",
        "        A.Resize(800, 800),\n",
        "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "        ToTensorV2()\n",
        "    ])\n",
        "\n",
        "    # Get all test images\n",
        "    img_files = sorted(TEST_IMG_DIR.glob(\"*.png\"))\n",
        "    print(f\"ðŸ“‚ Found {len(img_files)} test images\")\n",
        "\n",
        "    # Create dataset and dataloader\n",
        "    test_dataset = TestDataset(img_files, transform)\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=4,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # Batch processing with dual GPU\n",
        "    for batch_imgs, batch_boosts, batch_ids in tqdm(test_loader, desc=\"Processing Batches\"):\n",
        "        batch_imgs = batch_imgs.to(DEVICE)\n",
        "\n",
        "        # Inference on batch\n",
        "        with torch.no_grad():\n",
        "            # 1. Route to terrain (batch)\n",
        "            router_out = models['router'](batch_imgs)\n",
        "            t_ids = torch.argmax(router_out, dim=1).cpu().numpy()\n",
        "\n",
        "            # 2. Process each terrain type in batch\n",
        "            for i in range(len(batch_imgs)):\n",
        "                t_id = int(t_ids[i])\n",
        "                image_id = batch_ids[i]\n",
        "                boost = batch_boosts[i].cpu().numpy()\n",
        "\n",
        "                # Single image inference through specialist\n",
        "                x_single = batch_imgs[i:i+1]\n",
        "                spec_out = models[t_id](x_single)\n",
        "                seg_logits = spec_out[0] if isinstance(spec_out, tuple) else spec_out\n",
        "\n",
        "                # Ensure 20x20 output\n",
        "                if seg_logits.shape[-1] != 20:\n",
        "                    seg_logits = torch.nn.functional.interpolate(\n",
        "                        seg_logits, (20, 20), mode='bilinear', align_corners=False\n",
        "                    )\n",
        "\n",
        "                probs = torch.softmax(seg_logits, dim=1).squeeze().cpu().numpy()\n",
        "                grid = np.argmax(probs, axis=0)\n",
        "\n",
        "                # 3. Pathfinding (CPU-bound, runs in parallel with GPU)\n",
        "                path_str, _ = solve_path(grid, probs, boost, t_id)\n",
        "\n",
        "                results.append({\n",
        "                    'image_id': image_id,\n",
        "                    'path': path_str if path_str else \"\"\n",
        "                })\n",
        "\n",
        "    # Create DataFrame and save\n",
        "    df = pd.DataFrame(results)\n",
        "    df.to_csv(OUTPUT_CSV, index=False)\n",
        "\n",
        "    print(f\"\\nâœ… Submission saved to: {OUTPUT_CSV}\")\n",
        "    print(f\"ðŸ“Š Total samples: {len(df)}\")\n",
        "    print(f\"ðŸ“Š Paths found: {(df['path'] != '').sum()}\")\n",
        "    print(f\"ðŸ“Š No path found: {(df['path'] == '').sum()}\")\n",
        "\n",
        "    # Show sample\n",
        "    print(\"\\nðŸ“‹ Sample submissions:\")\n",
        "    print(df.head(10))\n",
        "\n",
        "    return df\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    submission_df = generate_submission()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-18T16:38:13.372187Z",
          "iopub.execute_input": "2025-12-18T16:38:13.372789Z",
          "iopub.status.idle": "2025-12-18T16:51:31.386467Z",
          "shell.execute_reply.started": "2025-12-18T16:38:13.372761Z",
          "shell.execute_reply": "2025-12-18T16:51:31.385808Z"
        },
        "id": "h4jcRIbJqyQm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "MAIN_SUBMISSION_FILE = \"/kaggle/working/submission.csv\"        # The file you just generated\n",
        "FALLBACK_SUBMISSION_FILE = \"/kaggle/input/subfill4/submission_filled(4).csv\" # <--- UPDATE THIS PATH\n",
        "OUTPUT_FILENAME = \"submis.csv\"     # The final file name\n",
        "\n",
        "def patch_submission():\n",
        "    # 1. Load Dataframes\n",
        "    print(f\"ðŸ“‚ Loading main file: {MAIN_SUBMISSION_FILE}\")\n",
        "    if not Path(MAIN_SUBMISSION_FILE).exists():\n",
        "        print(\"âŒ Main submission file not found!\")\n",
        "        return\n",
        "\n",
        "    df_main = pd.read_csv(MAIN_SUBMISSION_FILE)\n",
        "\n",
        "    print(f\"ðŸ“‚ Loading fallback file: {FALLBACK_SUBMISSION_FILE}\")\n",
        "    if not Path(FALLBACK_SUBMISSION_FILE).exists():\n",
        "        print(\"âŒ Fallback file not found!\")\n",
        "        return\n",
        "\n",
        "    df_fallback = pd.read_csv(FALLBACK_SUBMISSION_FILE)\n",
        "\n",
        "    # 2. Check Column Names (Standardize to 'image_id' and 'path')\n",
        "    # If your files use 'filename', rename it to 'image_id' for consistency\n",
        "    if 'filename' in df_main.columns:\n",
        "        df_main.rename(columns={'filename': 'image_id'}, inplace=True)\n",
        "    if 'filename' in df_fallback.columns:\n",
        "        df_fallback.rename(columns={'filename': 'image_id'}, inplace=True)\n",
        "\n",
        "    # 3. Create a dictionary map from the fallback file\n",
        "    # { 'image_001.png': 'rrdd...' }\n",
        "    fallback_map = df_fallback.set_index('image_id')['path'].to_dict()\n",
        "\n",
        "    # 4. Identify \"NO PATH\" entries\n",
        "    # Check for \"NO PATH\", empty strings, or NaNs\n",
        "    missing_mask = (df_main['path'] == \"NO PATH\") | (df_main['path'].isna()) | (df_main['path'] == \"\")\n",
        "    missing_count = missing_mask.sum()\n",
        "\n",
        "    print(f\"âš ï¸ Found {missing_count} rows with 'NO PATH'. Attempting to patch...\")\n",
        "\n",
        "    # 5. Patch Logic\n",
        "    patched_count = 0\n",
        "\n",
        "    def fill_path(row):\n",
        "        nonlocal patched_count\n",
        "        current_path = row['path']\n",
        "        img_id = row['image_id']\n",
        "\n",
        "        # If current path is invalid\n",
        "        if current_path == \"d\" or pd.isna(current_path) or current_path == \"\":\n",
        "            # Try to find in fallback\n",
        "            if img_id in fallback_map:\n",
        "                backup_path = fallback_map[img_id]\n",
        "                # Only use backup if it is NOT \"NO PATH\" itself\n",
        "                if backup_path != \"NO PATH\" and not pd.isna(backup_path):\n",
        "                    patched_count += 1\n",
        "                    return backup_path\n",
        "\n",
        "        return current_path\n",
        "\n",
        "    # Apply the patch\n",
        "    df_main['path'] = df_main.apply(fill_path, axis=1)\n",
        "\n",
        "    # 6. Save\n",
        "    df_main.to_csv(OUTPUT_FILENAME, index=False)\n",
        "\n",
        "    print(f\"âœ… Patch Complete!\")\n",
        "    print(f\"   - Replaced: {patched_count}/{missing_count} missing paths.\")\n",
        "    print(f\"   - Remaining 'NO PATH': {(df_main['path'] == 'NO PATH').sum()}\")\n",
        "    print(f\"   - Saved to: {OUTPUT_FILENAME}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    patch_submission()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-18T17:00:44.580059Z",
          "iopub.execute_input": "2025-12-18T17:00:44.580909Z",
          "iopub.status.idle": "2025-12-18T17:00:44.690482Z",
          "shell.execute_reply.started": "2025-12-18T17:00:44.580871Z",
          "shell.execute_reply": "2025-12-18T17:00:44.68985Z"
        },
        "id": "LjpSN9NQqyQm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "vIGUKyrKqyQn"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}