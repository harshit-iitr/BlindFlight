{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diXyFi_PoZGc"
      },
      "outputs": [],
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdXM189OoZGg"
      },
      "outputs": [],
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "the_blind_flight_synapse_drive_ps_1_path = kagglehub.competition_download('the-blind-flight-synapse-drive-ps-1')\n",
        "championsproo_subfill4_path = kagglehub.dataset_download('championsproo/subfill4')\n",
        "championsproo_blindflightclassmaping_path = kagglehub.dataset_download('championsproo/blindflightclassmaping')\n",
        "championsproo_blindflightv13_pytorch_default_1_path = kagglehub.model_download('championsproo/blindflightv13/PyTorch/default/1')\n",
        "\n",
        "print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-12-22T10:19:04.158862Z",
          "iopub.status.busy": "2025-12-22T10:19:04.158507Z",
          "iopub.status.idle": "2025-12-22T10:19:59.768763Z",
          "shell.execute_reply": "2025-12-22T10:19:59.768096Z",
          "shell.execute_reply.started": "2025-12-22T10:19:04.158832Z"
        },
        "id": "MIIINClaoZGh",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "# ==========================================\n",
        "# 1. CONFIGURATION\n",
        "# ==========================================\n",
        "ASSETS_ROOT = Path(\"/kaggle/input/the-blind-flight-synapse-drive-ps-1/SynapseDrive_Dataset/assets\")\n",
        "OUTPUT_DIR = Path(\"./generated_dataset_final_v13\")\n",
        "IMG_SIZE = 128\n",
        "BASE_SAMPLES = 2000\n",
        "\n",
        "# ==========================================\n",
        "# 2. MAPPING\n",
        "# ==========================================\n",
        "ASSET_MAP = {\n",
        "    \"t1_sand\": \"Desert_Road\", \"t1_cacti\": \"Desert_Cacti\", \"t1_rocks\": \"Desert_Rocks\",\n",
        "    \"t1_quicksand\": \"Desert_Hazard\", \"t1_rover\": \"Desert_Start\", \"t1_goal\": \"Desert_End\",\n",
        "\n",
        "    \"t0_dirt\": \"Forest_Road\", \"t0_tree\": \"Forest_Tree\", \"t0_puddle\": \"Forest_Hazard\",\n",
        "    \"t0_startship\": \"Forest_Start\", \"t0_goal\": \"Forest_End\",\n",
        "\n",
        "    \"t2_floor\": \"Lab_Road\", \"t2_wall\": \"Lab_Wall\", \"t2_plasma\": \"Lab_Plasma\",\n",
        "    \"t2_glue\": \"Lab_Hazard\", \"t2_drone\": \"Lab_Start\", \"t2_goal\": \"Lab_End\",\n",
        "}\n",
        "\n",
        "# ==========================================\n",
        "# 3. AUGMENTATION ENGINES\n",
        "# ==========================================\n",
        "def apply_soft_blur(img):\n",
        "    k = random.choice([3, 5])\n",
        "    return cv2.GaussianBlur(img, (k, k), 0)\n",
        "\n",
        "def apply_diagonal_cut(img):\n",
        "    if not img.flags['C_CONTIGUOUS']: img = np.ascontiguousarray(img)\n",
        "    h, w = img.shape[:2]\n",
        "    corner = random.choice(['tl', 'tr', 'bl', 'br'])\n",
        "    cut_size = random.randint(30, 60)\n",
        "    pts = []\n",
        "    if corner == 'tl': pts = np.array([[0,0], [cut_size,0], [0,cut_size]])\n",
        "    elif corner == 'tr': pts = np.array([[w,0], [w-cut_size,0], [w,cut_size]])\n",
        "    elif corner == 'bl': pts = np.array([[0,h], [cut_size,h], [0,h-cut_size]])\n",
        "    elif corner == 'br': pts = np.array([[w,h], [w-cut_size,h], [w,h-cut_size]])\n",
        "    cv2.fillPoly(img, [pts], (0, 0, 0))\n",
        "    return img\n",
        "\n",
        "def apply_tint(img):\n",
        "    if random.random() > 0.8: return img\n",
        "    overlay = np.zeros_like(img)\n",
        "    mode = random.choice([\"Cyan\", \"Purple\", \"Yellow\", \"Blue\", \"Green\", \"Red\", \"Dark\"])\n",
        "    b, g, r = 0, 0, 0\n",
        "    intensity = random.randint(30, 70)\n",
        "    if mode == \"Cyan\": b, g = intensity+40, intensity+40\n",
        "    elif mode == \"Purple\": b, r = intensity+40, intensity+40\n",
        "    elif mode == \"Yellow\": g, r = intensity+40, intensity+40\n",
        "    elif mode == \"Blue\": b = intensity+60\n",
        "    elif mode == \"Green\": g = intensity+60\n",
        "    elif mode == \"Red\": r = intensity+60\n",
        "    overlay[:] = (b, g, r)\n",
        "    return cv2.addWeighted(img, 0.75, overlay, 0.25, 0)\n",
        "\n",
        "def augment_v13_boosted(img, label, force_mirror=False):\n",
        "    aug = img.copy()\n",
        "\n",
        "    # 1. Base Rotation\n",
        "    k = random.choice([0, 1, 2, 3])\n",
        "    aug = np.rot90(aug, k)\n",
        "    aug = np.ascontiguousarray(aug)\n",
        "\n",
        "    # 2. Mirroring (Forced or Random)\n",
        "    if force_mirror:\n",
        "        aug = cv2.flip(aug, 1) # Force flip horizontal\n",
        "    elif random.random() > 0.5:\n",
        "        aug = cv2.flip(aug, 1)\n",
        "\n",
        "    is_vip = \"Start\" in label or \"End\" in label\n",
        "\n",
        "    # 3. Diagonal Cut (SKIP for VIPs)\n",
        "    if not is_vip and random.random() > 0.8:\n",
        "        aug = apply_diagonal_cut(aug)\n",
        "\n",
        "    # 4. Soft Blur (SKIP for VIPs)\n",
        "    if not is_vip and random.random() > 0.7:\n",
        "        aug = apply_soft_blur(aug)\n",
        "\n",
        "    # 5. Tints (Everyone gets lighting changes)\n",
        "    aug = apply_tint(aug)\n",
        "\n",
        "    return aug\n",
        "\n",
        "# ==========================================\n",
        "# 4. GENERATOR\n",
        "# ==========================================\n",
        "def generate_final_dataset():\n",
        "    if OUTPUT_DIR.exists():\n",
        "        import shutil\n",
        "        shutil.rmtree(OUTPUT_DIR)\n",
        "    OUTPUT_DIR.mkdir(parents=True)\n",
        "\n",
        "    all_assets = list(ASSETS_ROOT.rglob(\"*.png\"))\n",
        "    total_images = 0\n",
        "\n",
        "    print(f\"Generating V13 (Rover Boost + Mirroring)...\")\n",
        "\n",
        "    for asset_path in all_assets:\n",
        "        filename = asset_path.name.lower().replace(\".png\", \"\")\n",
        "        class_label = None\n",
        "        for key, label in ASSET_MAP.items():\n",
        "            if key in filename:\n",
        "                class_label = label\n",
        "                break\n",
        "\n",
        "        if class_label is None:\n",
        "            if \"rover\" in filename: class_label = \"Desert_Start\"\n",
        "            elif \"startship\" in filename: class_label = \"Forest_Start\"\n",
        "            elif \"drone\" in filename: class_label = \"Lab_Start\"\n",
        "            elif \"goal\" in filename:\n",
        "                if \"t0\" in filename: class_label = \"Forest_End\"\n",
        "                elif \"t1\" in filename: class_label = \"Desert_End\"\n",
        "                elif \"t2\" in filename: class_label = \"Lab_End\"\n",
        "                else: class_label = \"Desert_End\"\n",
        "            else: continue\n",
        "\n",
        "        class_dir = OUTPUT_DIR / class_label\n",
        "        class_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        original = cv2.imread(str(asset_path))\n",
        "        if original is None: continue\n",
        "        original = cv2.resize(original, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "        # --- OVERSAMPLING LOGIC ---\n",
        "        # If it's the tricky Desert Rover, generate 3x samples!\n",
        "        current_target = BASE_SAMPLES\n",
        "        if class_label == \"Desert_Start\":\n",
        "            current_target = BASE_SAMPLES * 3\n",
        "            print(f\"   >>> Boosting {class_label} to {current_target} samples\")\n",
        "\n",
        "        for i in range(current_target):\n",
        "            # Force half of the boosted set to be mirrored\n",
        "            force_flip = (i % 2 == 0)\n",
        "            img = augment_v13_boosted(original, class_label, force_mirror=force_flip)\n",
        "\n",
        "            cv2.imwrite(str(class_dir / f\"{class_label}_{i}.png\"), img)\n",
        "            total_images += 1\n",
        "\n",
        "    print(f\"âœ… V13 Dataset Ready ({total_images} images).\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    generate_final_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-22T10:22:10.902103Z",
          "iopub.status.busy": "2025-12-22T10:22:10.901709Z",
          "iopub.status.idle": "2025-12-22T10:22:12.744576Z",
          "shell.execute_reply": "2025-12-22T10:22:12.742402Z",
          "shell.execute_reply.started": "2025-12-22T10:22:10.902077Z"
        },
        "id": "JQi7ARr_oZGj",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import random\n",
        "from pathlib import Path\n",
        "import math\n",
        "\n",
        "# ==========================================\n",
        "# CONFIGURATION\n",
        "# ==========================================\n",
        "DATASET_DIR = Path(\"/kaggle/working/generated_dataset_final_v13\")\n",
        "SAMPLES_TO_SHOW = 20  # Total images to display\n",
        "\n",
        "def visualize_dataset():\n",
        "    if not DATASET_DIR.exists():\n",
        "        print(f\"âŒ Error: Directory {DATASET_DIR} not found. Run generator first.\")\n",
        "        return\n",
        "\n",
        "    # 1. Gather all image paths with their labels\n",
        "    all_images = []\n",
        "    classes = [d.name for d in DATASET_DIR.iterdir() if d.is_dir()]\n",
        "\n",
        "    print(f\"Found classes: {classes}\")\n",
        "\n",
        "    for cls in classes:\n",
        "        cls_dir = DATASET_DIR / cls\n",
        "        imgs = list(cls_dir.glob(\"*.png\"))\n",
        "        for img in imgs:\n",
        "            all_images.append((img, cls))\n",
        "\n",
        "    if not all_images:\n",
        "        print(\"âŒ No images found.\")\n",
        "        return\n",
        "\n",
        "    # 2. Pick Random Samples\n",
        "    samples = random.sample(all_images, min(len(all_images), SAMPLES_TO_SHOW))\n",
        "\n",
        "    # 3. Plot Grid\n",
        "    cols = 5\n",
        "    rows = math.ceil(len(samples) / cols)\n",
        "\n",
        "    plt.figure(figsize=(15, 3 * rows))\n",
        "\n",
        "    for i, (img_path, label) in enumerate(samples):\n",
        "        # Load exactly as the model would (resizing logic is already baked into the file)\n",
        "        img = cv2.imread(str(img_path))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        plt.subplot(rows, cols, i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"{label}\\n{img.shape}\", fontsize=9)\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    visualize_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-22T10:29:43.641945Z",
          "iopub.status.busy": "2025-12-22T10:29:43.641065Z",
          "iopub.status.idle": "2025-12-22T10:37:24.305542Z",
          "shell.execute_reply": "2025-12-22T10:37:24.304605Z",
          "shell.execute_reply.started": "2025-12-22T10:29:43.641902Z"
        },
        "id": "Vfg9-nJnoZGk",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import json\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ==========================================\n",
        "# 1. CONFIGURATION\n",
        "# ==========================================\n",
        "DATA_DIR = Path(\"/kaggle/working/generated_dataset_final_v13\")\n",
        "MODEL_SAVE_PATH = \"terrain_classifier_resnet_v12_1.pth\"\n",
        "MAPPING_SAVE_PATH = \"class_mapping.json\"\n",
        "BATCH_SIZE = 128  # Large batch size to feed both GPUs\n",
        "EPOCHS = 15\n",
        "LEARNING_RATE = 0.0001\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ==========================================\n",
        "# 2. DATA LOADING (128x128)\n",
        "# ==========================================\n",
        "# Normalization matches ImageNet stats (ResNet standard)\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "full_dataset = datasets.ImageFolder(root=DATA_DIR, transform=transform)\n",
        "train_size = int(0.9 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "# num_workers=4 ensures the CPU loads data fast enough to keep GPUs busy\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "# ==========================================\n",
        "# 3. DUAL-GPU MODEL SETUP\n",
        "# ==========================================\n",
        "print(\"ðŸš€ Building ResNet-18 (V10 Battle Mode)...\")\n",
        "model = models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, len(full_dataset.classes))\n",
        "\n",
        "# --- DUAL GPU ACTIVATION ---\n",
        "if torch.cuda.device_count() > 1:\n",
        "    print(f\"ðŸ”¥ Twin-Turbo Active: Using {torch.cuda.device_count()} GPUs!\")\n",
        "    model = nn.DataParallel(model)\n",
        "else:\n",
        "    print(\"âš ï¸ Single GPU Mode.\")\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# Optimization\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-3)\n",
        "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001, steps_per_epoch=len(train_loader), epochs=EPOCHS)\n",
        "\n",
        "# ==========================================\n",
        "# 4. TRAINING LOOP\n",
        "# ==========================================\n",
        "print(f\"Starting Training on {len(full_dataset.classes)} classes...\")\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\", leave=False)\n",
        "    for images, labels in loop:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: Val Acc = {100 * correct / total:.2f}%\")\n",
        "\n",
        "# ==========================================\n",
        "# 5. SAVE (Unwrap DataParallel)\n",
        "# ==========================================\n",
        "if isinstance(model, nn.DataParallel):\n",
        "    torch.save(model.module.state_dict(), MODEL_SAVE_PATH)\n",
        "else:\n",
        "    torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "\n",
        "idx_to_class = {v: k for k, v in full_dataset.class_to_idx.items()}\n",
        "with open(MAPPING_SAVE_PATH, 'w') as f:\n",
        "    json.dump(idx_to_class, f)\n",
        "\n",
        "print(f\"âœ… Saved Model to {MODEL_SAVE_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-22T10:59:48.627495Z",
          "iopub.status.busy": "2025-12-22T10:59:48.627189Z",
          "iopub.status.idle": "2025-12-22T11:00:18.320183Z",
          "shell.execute_reply": "2025-12-22T11:00:18.318856Z",
          "shell.execute_reply.started": "2025-12-22T10:59:48.627468Z"
        },
        "id": "ZR57KgIJoZGk",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms, models\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import heapq\n",
        "import json\n",
        "from pathlib import Path\n",
        "from sklearn.cluster import DBSCAN\n",
        "import random\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# ==========================================\n",
        "# 1. CONFIGURATION\n",
        "# ==========================================\n",
        "MODEL_PATH = \"terrain_classifier_resnet_v12_1.pth\"\n",
        "MAPPING_PATH = \"class_mapping.json\"\n",
        "TEST_IMG_DIR = Path(\"/kaggle/input/the-blind-flight-synapse-drive-ps-1/SynapseDrive_Dataset/test/images\")\n",
        "CELL_SIZE = 64\n",
        "MAX_ROWS = 20\n",
        "MAX_COLS = 20\n",
        "NUM_SAMPLES = 40\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "COST_TABLES = {\n",
        "    \"Desert\": {\"Road\": 1.2, \"Start\": 1.2, \"End\": 2.2, \"Hazard\": 3.7, \"Cacti\": 999.0, \"Rocks\": 999.0, \"Obstacle\": 999.0, \"Unknown\": 8.0},\n",
        "    \"Forest\": {\"Road\": 1.5, \"Start\": 1.5, \"End\": 2.5, \"Hazard\": 2.8, \"Tree\": 999.0, \"Obstacle\": 999.0, \"Unknown\": 8.0},\n",
        "    \"Lab\": {\"Road\": 1.0, \"Start\": 1.0, \"End\": 2.0, \"Hazard\": 3.0, \"Wall\": 999.0, \"Plasma\": 999.0, \"Obstacle\": 999.0, \"Unknown\": 8.0}\n",
        "}\n",
        "\n",
        "# ==========================================\n",
        "# 2. VISION HELPERS (Grid Extraction)\n",
        "# ==========================================\n",
        "def preprocess_for_grid(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    no_texture = cv2.medianBlur(gray, 7)\n",
        "    thresh = cv2.adaptiveThreshold(no_texture, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 19, 5)\n",
        "    return thresh\n",
        "\n",
        "def get_intersections(img):\n",
        "    thresh = preprocess_for_grid(img)\n",
        "    scale = 25\n",
        "    h_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (scale, 1))\n",
        "    v_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, scale))\n",
        "    mask_h = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, h_kernel)\n",
        "    mask_v = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, v_kernel)\n",
        "    intersections = cv2.bitwise_and(mask_h, mask_v)\n",
        "    intersections = cv2.dilate(intersections, np.ones((5,5)))\n",
        "    num_labels, _, stats, centroids = cv2.connectedComponentsWithStats(intersections)\n",
        "    points = [centroids[i] for i in range(1, num_labels) if stats[i, cv2.CC_STAT_AREA] > 10]\n",
        "    if not points: return np.array([])\n",
        "    clustering = DBSCAN(eps=20, min_samples=1).fit(points)\n",
        "    points = np.array(points)\n",
        "    clean_points = [np.mean(points[clustering.labels_ == label], axis=0) for label in set(clustering.labels_)]\n",
        "    return np.array(clean_points)\n",
        "\n",
        "def sort_points_robust(points):\n",
        "    y_clustering = DBSCAN(eps=25, min_samples=3).fit(points[:, 1].reshape(-1, 1))\n",
        "    rows_dict = {}\n",
        "    for pt, label in zip(points, y_clustering.labels_):\n",
        "        if label == -1: continue\n",
        "        if label not in rows_dict: rows_dict[label] = []\n",
        "        rows_dict[label].append(pt)\n",
        "    sorted_keys = sorted(rows_dict.keys(), key=lambda k: np.mean([p[1] for p in rows_dict[k]]))\n",
        "    return [np.array(sorted(rows_dict[k], key=lambda p: p[0])) for k in sorted_keys]\n",
        "\n",
        "def get_global_column_grid(grid_rows):\n",
        "    all_x = [pt[0] for row in grid_rows for pt in row]\n",
        "    if not all_x: return np.array([])\n",
        "    all_x = np.array(all_x).reshape(-1, 1)\n",
        "    clustering = DBSCAN(eps=15, min_samples=1).fit(all_x)\n",
        "    col_centers = [np.mean(all_x[clustering.labels_ == label]) for label in set(clustering.labels_) if label != -1]\n",
        "    return np.array(sorted(col_centers))\n",
        "\n",
        "def extract_grid_data(image_path):\n",
        "    img = cv2.imread(str(image_path))\n",
        "    if img is None: return None, None, \"Load Error\"\n",
        "\n",
        "    grid_tensor = np.zeros((MAX_ROWS, MAX_COLS, CELL_SIZE, CELL_SIZE, 3), dtype=np.uint8)\n",
        "    mask_tensor = np.zeros((MAX_ROWS, MAX_COLS), dtype=np.uint8)\n",
        "\n",
        "    try:\n",
        "        points = get_intersections(img)\n",
        "        if len(points) < 40: return grid_tensor, mask_tensor, \"Fallback: Low Pts\"\n",
        "        grid_rows = sort_points_robust(points)\n",
        "        if len(grid_rows) < 4: return grid_tensor, mask_tensor, \"Fallback: Few Rows\"\n",
        "        col_centers = get_global_column_grid(grid_rows)\n",
        "        if len(col_centers) < 2: return grid_tensor, mask_tensor, \"Fallback: No Cols\"\n",
        "\n",
        "        for r in range(min(len(grid_rows) - 1, MAX_ROWS)):\n",
        "            row_top = grid_rows[r]\n",
        "            row_btm = grid_rows[r+1]\n",
        "            for pt_top in row_top:\n",
        "                neighbors_tr = [p for p in row_top if p[0] > pt_top[0]]\n",
        "                if not neighbors_tr: continue\n",
        "                pt_tr = min(neighbors_tr, key=lambda p: p[0])\n",
        "                if abs(pt_tr[0] - pt_top[0]) > 100: continue\n",
        "                candidates_bl = [p for p in row_btm if abs(p[0] - pt_top[0]) < 70]\n",
        "                if not candidates_bl: continue\n",
        "                pt_bl = min(candidates_bl, key=lambda p: abs(p[0] - pt_top[0]))\n",
        "                candidates_br = [p for p in row_btm if abs(p[0] - pt_tr[0]) < 70]\n",
        "                if not candidates_br: continue\n",
        "                pt_br = min(candidates_br, key=lambda p: abs(p[0] - pt_tr[0]))\n",
        "\n",
        "                src = np.array([pt_top, pt_tr, pt_br, pt_bl], dtype=\"float32\")\n",
        "                dst = np.array([[0,0], [CELL_SIZE,0], [CELL_SIZE,CELL_SIZE], [0,CELL_SIZE]], dtype=\"float32\")\n",
        "                M = cv2.getPerspectiveTransform(src, dst)\n",
        "                warped = cv2.warpPerspective(img, M, (CELL_SIZE, CELL_SIZE))\n",
        "\n",
        "                diffs = np.abs(col_centers - pt_top[0])\n",
        "                c_idx = np.argmin(diffs)\n",
        "                if c_idx < MAX_COLS:\n",
        "                    grid_tensor[r, c_idx] = warped\n",
        "                    mask_tensor[r, c_idx] = 1\n",
        "        return grid_tensor, mask_tensor, \"Active: Gridded\"\n",
        "    except: return grid_tensor, mask_tensor, \"Error\"\n",
        "\n",
        "# ==========================================\n",
        "# 3. MODEL LOADING (Standard ResNet Mode)\n",
        "# ==========================================\n",
        "with open(MAPPING_PATH, 'r') as f:\n",
        "    idx_to_class = json.load(f)\n",
        "    idx_to_class = {int(k): v for k, v in idx_to_class.items()}\n",
        "\n",
        "# Construct Standard ResNet-18 (Matches your saved file)\n",
        "model = models.resnet18(pretrained=False)\n",
        "\n",
        "# --- THE FIX: DO NOT RUN THESE LINES ---\n",
        "# model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "# model.maxpool = nn.Identity()\n",
        "# ---------------------------------------\n",
        "\n",
        "model.fc = nn.Linear(model.fc.in_features, len(idx_to_class))\n",
        "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# We still use 128x128 input because that's what we sliced,\n",
        "# but Standard ResNet will just downsample it. That's fine.\n",
        "transform_pipe = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# ==========================================\n",
        "# 4. SOLVER PROCESSOR\n",
        "# ==========================================\n",
        "def process_single_image(image_path):\n",
        "    grid_tensor, mask_tensor, status = extract_grid_data(image_path)\n",
        "    if \"Active\" not in status: return None, \"Slicer Fail\"\n",
        "\n",
        "    rows, cols = mask_tensor.shape\n",
        "    batch_tensors = []\n",
        "    coords = []\n",
        "\n",
        "    for r in range(rows):\n",
        "        for c in range(cols):\n",
        "            if mask_tensor[r, c] == 1:\n",
        "                # BGR -> RGB\n",
        "                rgb_cell = cv2.cvtColor(grid_tensor[r, c], cv2.COLOR_BGR2RGB)\n",
        "                batch_tensors.append(transform_pipe(rgb_cell))\n",
        "                coords.append((r, c))\n",
        "\n",
        "    if not batch_tensors: return None, \"Empty Grid\"\n",
        "\n",
        "    batch_stack = torch.stack(batch_tensors).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(batch_stack)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "    terrain_map = np.full((rows, cols), \"Unknown\", dtype=object)\n",
        "    counts = {\"Desert\": 0, \"Forest\": 0, \"Lab\": 0}\n",
        "\n",
        "    for i, (r, c) in enumerate(coords):\n",
        "        class_name = idx_to_class[preds[i].item()]\n",
        "        terrain_map[r, c] = class_name\n",
        "\n",
        "        biome = class_name.split(\"_\")[0] if \"_\" in class_name else \"Lab\"\n",
        "        weight = 3 if any(x in class_name for x in [\"Cacti\", \"Tree\", \"Plasma\", \"Wall\", \"Rocks\"]) else 1\n",
        "        if \"Start\" in class_name or \"End\" in class_name: weight = 5\n",
        "        counts[biome] = counts.get(biome, 0) + weight\n",
        "\n",
        "    dominant_biome = max(counts, key=counts.get) if counts else \"Lab\"\n",
        "    costs = COST_TABLES.get(dominant_biome, COST_TABLES[\"Lab\"])\n",
        "\n",
        "    start_pos, end_pos = None, None\n",
        "    for r in range(rows):\n",
        "        for c in range(cols):\n",
        "            if \"Start\" in terrain_map[r, c]: start_pos = (r, c)\n",
        "            if \"End\" in terrain_map[r, c]: end_pos = (r, c)\n",
        "\n",
        "    path = []\n",
        "    status_msg = \"No Path\"\n",
        "\n",
        "    if start_pos and end_pos:\n",
        "        pq = [(0, start_pos)]\n",
        "        cost_so_far = {start_pos: 0}\n",
        "        came_from = {}\n",
        "\n",
        "        while pq:\n",
        "            curr_cost, curr = heapq.heappop(pq)\n",
        "            if curr == end_pos:\n",
        "                status_msg = \"Solved\"\n",
        "                break\n",
        "\n",
        "            r, c = curr\n",
        "            for nr, nc in [(r-1,c), (r+1,c), (r,c-1), (r,c+1)]:\n",
        "                if 0 <= nr < rows and 0 <= nc < cols:\n",
        "                    label = terrain_map[nr, nc]\n",
        "                    if label == \"Unknown\": cell_type = \"Unknown\"\n",
        "                    else: cell_type = label.split(\"_\")[1] if \"_\" in label else label\n",
        "\n",
        "                    step_cost = costs.get(cell_type, 999.0)\n",
        "                    new_cost = cost_so_far[curr] + step_cost\n",
        "\n",
        "                    if step_cost < 100:\n",
        "                        if (nr, nc) not in cost_so_far or new_cost < cost_so_far[(nr, nc)]:\n",
        "                            cost_so_far[(nr, nc)] = new_cost\n",
        "                            heapq.heappush(pq, (new_cost + abs(nr-end_pos[0]) + abs(nc-end_pos[1]), (nr, nc)))\n",
        "                            came_from[(nr, nc)] = curr\n",
        "\n",
        "        if status_msg == \"Solved\":\n",
        "            curr = end_pos\n",
        "            while curr != start_pos:\n",
        "                path.append(curr)\n",
        "                curr = came_from[curr]\n",
        "            path.append(start_pos)\n",
        "\n",
        "    # Visualization\n",
        "    img_vis = cv2.imread(str(image_path))\n",
        "    img_vis = cv2.resize(img_vis, (400, 400))\n",
        "    cell_h, cell_w = 400 // rows, 400 // cols\n",
        "\n",
        "    for r in range(rows):\n",
        "        for c in range(cols):\n",
        "            if mask_tensor[r, c] == 1:\n",
        "                lbl = terrain_map[r, c]\n",
        "                cx, cy = int((c + 0.5) * cell_w), int((r + 0.5) * cell_h)\n",
        "                color = (100, 100, 100)\n",
        "                if \"Start\" in lbl: color = (0, 255, 255)\n",
        "                if \"End\" in lbl: color = (0, 0, 255)\n",
        "                if any(x in lbl for x in [\"Obstacle\", \"Wall\", \"Tree\", \"Cacti\", \"Rocks\", \"Plasma\"]): color = (0, 0, 0)\n",
        "                if \"Hazard\" in lbl: color = (0, 165, 255)\n",
        "                cv2.circle(img_vis, (cx, cy), 3, color, -1)\n",
        "\n",
        "    if path:\n",
        "        for i in range(len(path) - 1):\n",
        "            p1 = (int((path[i][1]+0.5)*cell_w), int((path[i][0]+0.5)*cell_h))\n",
        "            p2 = (int((path[i+1][1]+0.5)*cell_w), int((path[i+1][0]+0.5)*cell_h))\n",
        "            cv2.line(img_vis, p1, p2, (0, 255, 0), 2)\n",
        "\n",
        "    return img_vis, f\"{dominant_biome}: {status_msg}\"\n",
        "\n",
        "# ==========================================\n",
        "# 5. EXECUTION\n",
        "# ==========================================\n",
        "test_files = list(TEST_IMG_DIR.glob(\"*.png\"))\n",
        "if test_files:\n",
        "    samples = random.sample(test_files, min(len(test_files), NUM_SAMPLES))\n",
        "    print(f\"Processing {len(samples)} images...\")\n",
        "    results = []\n",
        "    for img_path in tqdm(samples):\n",
        "        res_img, status = process_single_image(img_path)\n",
        "        if res_img is not None: results.append((res_img, status))\n",
        "\n",
        "    rows = (len(results) + 4) // 5\n",
        "    fig, axes = plt.subplots(rows, 5, figsize=(20, 4 * rows))\n",
        "    axes = axes.flatten()\n",
        "    for i, (img, status) in enumerate(results):\n",
        "        ax = axes[i]\n",
        "        ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "        title_color = 'green' if \"Solved\" in status else 'red'\n",
        "        ax.set_title(status, color=title_color, fontsize=10, fontweight='bold')\n",
        "        ax.axis('off')\n",
        "    for j in range(i + 1, len(axes)): axes[j].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No images found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-12-22T10:50:01.032045Z",
          "iopub.status.busy": "2025-12-22T10:50:01.031592Z",
          "iopub.status.idle": "2025-12-22T10:50:14.110721Z",
          "shell.execute_reply": "2025-12-22T10:50:14.109874Z",
          "shell.execute_reply.started": "2025-12-22T10:50:01.032011Z"
        },
        "id": "DUXMQUvsoZGm",
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": true
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from sklearn.cluster import DBSCAN\n",
        "import random\n",
        "\n",
        "# ==========================================\n",
        "# 1. CONFIGURATION\n",
        "# ==========================================\n",
        "TEST_IMG_DIR = Path(\"/kaggle/input/the-blind-flight-synapse-drive-ps-1/SynapseDrive_Dataset/test/images\")\n",
        "CELL_SIZE = 64\n",
        "MAX_ROWS = 20\n",
        "MAX_COLS = 20\n",
        "SAMPLES_TO_CHECK = 10  # How many maps to inspect\n",
        "\n",
        "# ==========================================\n",
        "# 2. THE EXACT VISION LOGIC (Copy-Paste from your pipeline)\n",
        "# ==========================================\n",
        "def preprocess_for_grid(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    no_texture = cv2.medianBlur(gray, 7)\n",
        "    thresh = cv2.adaptiveThreshold(no_texture, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                                   cv2.THRESH_BINARY_INV, 19, 5)\n",
        "    return thresh\n",
        "\n",
        "def get_intersections(img):\n",
        "    thresh = preprocess_for_grid(img)\n",
        "    scale = 25\n",
        "    h_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (scale, 1))\n",
        "    v_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, scale))\n",
        "    mask_h = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, h_kernel)\n",
        "    mask_v = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, v_kernel)\n",
        "    intersections = cv2.bitwise_and(mask_h, mask_v)\n",
        "    intersections = cv2.dilate(intersections, np.ones((5,5)))\n",
        "    num_labels, _, stats, centroids = cv2.connectedComponentsWithStats(intersections)\n",
        "    points = [centroids[i] for i in range(1, num_labels) if stats[i, cv2.CC_STAT_AREA] > 10]\n",
        "    if not points: return np.array([])\n",
        "    clustering = DBSCAN(eps=20, min_samples=1).fit(points)\n",
        "    points = np.array(points)\n",
        "    clean_points = [np.mean(points[clustering.labels_ == label], axis=0) for label in set(clustering.labels_)]\n",
        "    return np.array(clean_points)\n",
        "\n",
        "def sort_points_robust(points):\n",
        "    y_clustering = DBSCAN(eps=25, min_samples=3).fit(points[:, 1].reshape(-1, 1))\n",
        "    rows_dict = {}\n",
        "    for pt, label in zip(points, y_clustering.labels_):\n",
        "        if label == -1: continue\n",
        "        if label not in rows_dict: rows_dict[label] = []\n",
        "        rows_dict[label].append(pt)\n",
        "    sorted_keys = sorted(rows_dict.keys(), key=lambda k: np.mean([p[1] for p in rows_dict[k]]))\n",
        "    return [np.array(sorted(rows_dict[k], key=lambda p: p[0])) for k in sorted_keys]\n",
        "\n",
        "def get_global_column_grid(grid_rows):\n",
        "    all_x = [pt[0] for row in grid_rows for pt in row]\n",
        "    if not all_x: return np.array([])\n",
        "    all_x = np.array(all_x).reshape(-1, 1)\n",
        "    clustering = DBSCAN(eps=15, min_samples=1).fit(all_x)\n",
        "    col_centers = [np.mean(all_x[clustering.labels_ == label]) for label in set(clustering.labels_) if label != -1]\n",
        "    return np.array(sorted(col_centers))\n",
        "\n",
        "def extract_grid_data(img):\n",
        "    # Returns the visual grid tensor and mask\n",
        "    grid_tensor = np.zeros((MAX_ROWS, MAX_COLS, CELL_SIZE, CELL_SIZE, 3), dtype=np.uint8)\n",
        "    mask_tensor = np.zeros((MAX_ROWS, MAX_COLS), dtype=np.uint8)\n",
        "    debug_points = [] # To draw grid lines later\n",
        "\n",
        "    try:\n",
        "        points = get_intersections(img)\n",
        "        if len(points) < 40: return None, None, [], \"Fallback: Low Pts\"\n",
        "        grid_rows = sort_points_robust(points)\n",
        "        if len(grid_rows) < 4: return None, None, [], \"Fallback: Few Rows\"\n",
        "        col_centers = get_global_column_grid(grid_rows)\n",
        "        if len(col_centers) < 2: return None, None, [], \"Fallback: No Cols\"\n",
        "\n",
        "        for r in range(min(len(grid_rows) - 1, MAX_ROWS)):\n",
        "            row_top = grid_rows[r]\n",
        "            row_btm = grid_rows[r+1]\n",
        "            for pt_top in row_top:\n",
        "                # Find neighbors to build the quad\n",
        "                neighbors_tr = [p for p in row_top if p[0] > pt_top[0]]\n",
        "                if not neighbors_tr: continue\n",
        "                pt_tr = min(neighbors_tr, key=lambda p: p[0])\n",
        "                if abs(pt_tr[0] - pt_top[0]) > 100: continue\n",
        "\n",
        "                candidates_bl = [p for p in row_btm if abs(p[0] - pt_top[0]) < 70]\n",
        "                if not candidates_bl: continue\n",
        "                pt_bl = min(candidates_bl, key=lambda p: abs(p[0] - pt_top[0]))\n",
        "                candidates_br = [p for p in row_btm if abs(p[0] - pt_tr[0]) < 70]\n",
        "                if not candidates_br: continue\n",
        "                pt_br = min(candidates_br, key=lambda p: abs(p[0] - pt_tr[0]))\n",
        "\n",
        "                # Perspective Warp\n",
        "                src = np.array([pt_top, pt_tr, pt_br, pt_bl], dtype=\"float32\")\n",
        "                dst = np.array([[0,0], [CELL_SIZE,0], [CELL_SIZE,CELL_SIZE], [0,CELL_SIZE]], dtype=\"float32\")\n",
        "                M = cv2.getPerspectiveTransform(src, dst)\n",
        "                warped = cv2.warpPerspective(img, M, (CELL_SIZE, CELL_SIZE))\n",
        "\n",
        "                # Grid Mapping\n",
        "                diffs = np.abs(col_centers - pt_top[0])\n",
        "                c_idx = np.argmin(diffs)\n",
        "                if c_idx < MAX_COLS:\n",
        "                    grid_tensor[r, c_idx] = warped\n",
        "                    mask_tensor[r, c_idx] = 1\n",
        "                    debug_points.append(src) # Store quad for visualization\n",
        "\n",
        "        return grid_tensor, mask_tensor, debug_points, \"Active: Gridded\"\n",
        "    except Exception as e: return None, None, [], f\"Error: {e}\"\n",
        "\n",
        "# ==========================================\n",
        "# 3. VISUALIZATION LOOP\n",
        "# ==========================================\n",
        "test_files = list(TEST_IMG_DIR.glob(\"*.png\"))\n",
        "samples = random.sample(test_files, SAMPLES_TO_CHECK)\n",
        "\n",
        "for img_path in samples:\n",
        "    print(f\"\\nðŸ” Inspecting: {img_path.name}\")\n",
        "    original = cv2.imread(str(img_path))\n",
        "    original_vis = original.copy()\n",
        "\n",
        "    # 1. Run Slicer\n",
        "    grid, mask, debug_quads, status = extract_grid_data(original)\n",
        "\n",
        "    if \"Active\" not in status:\n",
        "        print(f\"âŒ Failed: {status}\")\n",
        "        plt.imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))\n",
        "        plt.title(f\"FAILED: {status}\")\n",
        "        plt.show()\n",
        "        continue\n",
        "\n",
        "    # 2. Draw Grid on Original\n",
        "    for quad in debug_quads:\n",
        "        pts = quad.astype(int)\n",
        "        # Draw Top Line\n",
        "        cv2.line(original_vis, tuple(pts[0]), tuple(pts[1]), (0, 255, 255), 2)\n",
        "        # Draw Right Line\n",
        "        cv2.line(original_vis, tuple(pts[1]), tuple(pts[2]), (0, 255, 255), 2)\n",
        "        # Draw Bottom Line\n",
        "        cv2.line(original_vis, tuple(pts[2]), tuple(pts[3]), (0, 255, 255), 2)\n",
        "        # Draw Left Line\n",
        "        cv2.line(original_vis, tuple(pts[3]), tuple(pts[0]), (0, 255, 255), 2)\n",
        "\n",
        "    # 3. Plotting\n",
        "    rows, cols = mask.shape\n",
        "    active_cells = []\n",
        "\n",
        "    # Collect all sliced images\n",
        "    for r in range(rows):\n",
        "        for c in range(cols):\n",
        "            if mask[r, c] == 1:\n",
        "                active_cells.append(grid[r, c])\n",
        "\n",
        "    # Figure 1: The \"Blueprint\" (Where we cut)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.imshow(cv2.cvtColor(original_vis, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(f\"Slicer Grid Overlay | Found {len(active_cells)} cells\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    # Figure 2: The \"Biopsy\" (What the model sees)\n",
        "    # Display first 20 extracted cells\n",
        "    num_show = min(len(active_cells), 20)\n",
        "    if num_show > 0:\n",
        "        fig, axes = plt.subplots(2, 10, figsize=(15, 4))\n",
        "        axes = axes.flatten()\n",
        "\n",
        "        for i in range(len(axes)):\n",
        "            if i < num_show:\n",
        "                cell_rgb = cv2.cvtColor(active_cells[i], cv2.COLOR_BGR2RGB)\n",
        "                axes[i].imshow(cell_rgb)\n",
        "                axes[i].set_title(f\"Cell {i}\")\n",
        "            axes[i].axis('off')\n",
        "        plt.suptitle(\"Extracted Input Tensors (64x64)\", fontsize=16)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"âš ï¸ No cells extracted despite success status.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-22T11:18:21.908951Z",
          "iopub.status.busy": "2025-12-22T11:18:21.908728Z",
          "iopub.status.idle": "2025-12-22T12:48:26.586729Z",
          "shell.execute_reply": "2025-12-22T12:48:26.586105Z",
          "shell.execute_reply.started": "2025-12-22T11:18:21.90893Z"
        },
        "id": "piqHWMjWoZGn",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms, models\n",
        "import cv2\n",
        "import numpy as np\n",
        "import heapq\n",
        "import json\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.cluster import DBSCAN\n",
        "from tqdm.auto import tqdm\n",
        "import re\n",
        "\n",
        "# ==========================================\n",
        "# 1. CONFIGURATION\n",
        "# ==========================================\n",
        "MODEL_PATH = \"/kaggle/input/blindflightv13/pytorch/default/1/terrain_classifier_resnet_v12_1.pth\"\n",
        "MAPPING_PATH = \"/kaggle/input/blindflightclassmaping/class_mapping (1).json\"\n",
        "TEST_IMG_DIR = Path(\"/kaggle/input/the-blind-flight-synapse-drive-ps-1/SynapseDrive_Dataset/test/images\")\n",
        "OUTPUT_CSV = \"submission.csv\"\n",
        "\n",
        "CELL_SIZE = 64\n",
        "MAX_ROWS = 20\n",
        "MAX_COLS = 20\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "COST_TABLES = {\n",
        "    \"Desert\": {\"Road\": 1.2, \"Start\": 1.2, \"End\": 2.2, \"Hazard\": 3.7, \"Cacti\": 999.0, \"Rocks\": 999.0, \"Obstacle\": 999.0, \"Unknown\": 8.0},\n",
        "    \"Forest\": {\"Road\": 1.5, \"Start\": 1.5, \"End\": 2.5, \"Hazard\": 2.8, \"Tree\": 999.0, \"Obstacle\": 999.0, \"Unknown\": 8.0},\n",
        "    \"Lab\": {\"Road\": 1.0, \"Start\": 1.0, \"End\": 2.0, \"Hazard\": 3.0, \"Wall\": 999.0, \"Plasma\": 999.0, \"Obstacle\": 999.0, \"Unknown\": 8.0}\n",
        "}\n",
        "\n",
        "# ==========================================\n",
        "# 2. VISION & GRID HELPERS\n",
        "# ==========================================\n",
        "def preprocess_for_grid(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    no_texture = cv2.medianBlur(gray, 7)\n",
        "    thresh = cv2.adaptiveThreshold(no_texture, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 19, 5)\n",
        "    return thresh\n",
        "\n",
        "def get_intersections(img):\n",
        "    thresh = preprocess_for_grid(img)\n",
        "    scale = 25\n",
        "    h_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (scale, 1))\n",
        "    v_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, scale))\n",
        "    mask_h = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, h_kernel)\n",
        "    mask_v = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, v_kernel)\n",
        "    intersections = cv2.bitwise_and(mask_h, mask_v)\n",
        "    intersections = cv2.dilate(intersections, np.ones((5,5)))\n",
        "    num_labels, _, stats, centroids = cv2.connectedComponentsWithStats(intersections)\n",
        "    points = [centroids[i] for i in range(1, num_labels) if stats[i, cv2.CC_STAT_AREA] > 10]\n",
        "    if not points: return np.array([])\n",
        "    clustering = DBSCAN(eps=20, min_samples=1).fit(points)\n",
        "    points = np.array(points)\n",
        "    clean_points = [np.mean(points[clustering.labels_ == label], axis=0) for label in set(clustering.labels_)]\n",
        "    return np.array(clean_points)\n",
        "\n",
        "def sort_points_robust(points):\n",
        "    y_clustering = DBSCAN(eps=25, min_samples=3).fit(points[:, 1].reshape(-1, 1))\n",
        "    rows_dict = {}\n",
        "    for pt, label in zip(points, y_clustering.labels_):\n",
        "        if label == -1: continue\n",
        "        if label not in rows_dict: rows_dict[label] = []\n",
        "        rows_dict[label].append(pt)\n",
        "    sorted_keys = sorted(rows_dict.keys(), key=lambda k: np.mean([p[1] for p in rows_dict[k]]))\n",
        "    return [np.array(sorted(rows_dict[k], key=lambda p: p[0])) for k in sorted_keys]\n",
        "\n",
        "def get_global_column_grid(grid_rows):\n",
        "    all_x = [pt[0] for row in grid_rows for pt in row]\n",
        "    if not all_x: return np.array([])\n",
        "    all_x = np.array(all_x).reshape(-1, 1)\n",
        "    clustering = DBSCAN(eps=15, min_samples=1).fit(all_x)\n",
        "    col_centers = [np.mean(all_x[clustering.labels_ == label]) for label in set(clustering.labels_) if label != -1]\n",
        "    return np.array(sorted(col_centers))\n",
        "\n",
        "def extract_grid_data(image_path):\n",
        "    img = cv2.imread(str(image_path))\n",
        "    if img is None: return None, None, \"Load Error\"\n",
        "\n",
        "    grid_tensor = np.zeros((MAX_ROWS, MAX_COLS, CELL_SIZE, CELL_SIZE, 3), dtype=np.uint8)\n",
        "    mask_tensor = np.zeros((MAX_ROWS, MAX_COLS), dtype=np.uint8)\n",
        "\n",
        "    try:\n",
        "        points = get_intersections(img)\n",
        "        if len(points) < 40: return grid_tensor, mask_tensor, \"Fallback: Low Pts\"\n",
        "        grid_rows = sort_points_robust(points)\n",
        "        if len(grid_rows) < 4: return grid_tensor, mask_tensor, \"Fallback: Few Rows\"\n",
        "        col_centers = get_global_column_grid(grid_rows)\n",
        "        if len(col_centers) < 2: return grid_tensor, mask_tensor, \"Fallback: No Cols\"\n",
        "\n",
        "        for r in range(min(len(grid_rows) - 1, MAX_ROWS)):\n",
        "            row_top = grid_rows[r]\n",
        "            row_btm = grid_rows[r+1]\n",
        "            for pt_top in row_top:\n",
        "                neighbors_tr = [p for p in row_top if p[0] > pt_top[0]]\n",
        "                if not neighbors_tr: continue\n",
        "                pt_tr = min(neighbors_tr, key=lambda p: p[0])\n",
        "                if abs(pt_tr[0] - pt_top[0]) > 100: continue\n",
        "                candidates_bl = [p for p in row_btm if abs(p[0] - pt_top[0]) < 70]\n",
        "                if not candidates_bl: continue\n",
        "                pt_bl = min(candidates_bl, key=lambda p: abs(p[0] - pt_top[0]))\n",
        "                candidates_br = [p for p in row_btm if abs(p[0] - pt_tr[0]) < 70]\n",
        "                if not candidates_br: continue\n",
        "                pt_br = min(candidates_br, key=lambda p: abs(p[0] - pt_tr[0]))\n",
        "\n",
        "                src = np.array([pt_top, pt_tr, pt_br, pt_bl], dtype=\"float32\")\n",
        "                dst = np.array([[0,0], [CELL_SIZE,0], [CELL_SIZE,CELL_SIZE], [0,CELL_SIZE]], dtype=\"float32\")\n",
        "                M = cv2.getPerspectiveTransform(src, dst)\n",
        "                warped = cv2.warpPerspective(img, M, (CELL_SIZE, CELL_SIZE))\n",
        "\n",
        "                diffs = np.abs(col_centers - pt_top[0])\n",
        "                c_idx = np.argmin(diffs)\n",
        "                if c_idx < MAX_COLS:\n",
        "                    grid_tensor[r, c_idx] = warped\n",
        "                    mask_tensor[r, c_idx] = 1\n",
        "        return grid_tensor, mask_tensor, \"Active: Gridded\"\n",
        "    except: return grid_tensor, mask_tensor, \"Error\"\n",
        "\n",
        "# ==========================================\n",
        "# 3. MODEL LOADING (FIXED FOR STANDARD RESNET)\n",
        "# ==========================================\n",
        "with open(MAPPING_PATH, 'r') as f:\n",
        "    idx_to_class = json.load(f)\n",
        "    idx_to_class = {int(k): v for k, v in idx_to_class.items()}\n",
        "\n",
        "print(\"ðŸš€ Loading V13 Model (Standard Architecture)...\")\n",
        "\n",
        "# 1. Base ResNet\n",
        "model = models.resnet18(pretrained=False)\n",
        "\n",
        "# --- FIX: DISABLED HACK TO MATCH SAVED FILE ---\n",
        "# The saved checkpoint has a 7x7 conv1, so we must use standard definition.\n",
        "# model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "# model.maxpool = nn.Identity()\n",
        "# ----------------------------------------------\n",
        "\n",
        "model.fc = nn.Linear(model.fc.in_features, len(idx_to_class))\n",
        "\n",
        "try:\n",
        "    state_dict = torch.load(MODEL_PATH, map_location=device)\n",
        "    model.load_state_dict(state_dict)\n",
        "except RuntimeError as e:\n",
        "    print(\"\\nâŒ LOAD ERROR! Model mismatch.\")\n",
        "    print(f\"Error details: {e}\\n\")\n",
        "    raise e\n",
        "\n",
        "if torch.cuda.device_count() > 1:\n",
        "    print(f\"ðŸ”¥ Twin-Turbo Active: {torch.cuda.device_count()} GPUs for Inference\")\n",
        "    model = nn.DataParallel(model)\n",
        "\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# We still feed 128x128 images. ResNet will just downsample them normally.\n",
        "transform_pipe = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# ==========================================\n",
        "# 4. PATH FORMATTER (LOWERCASE LDRU)\n",
        "# ==========================================\n",
        "def path_coords_to_string(path_list):\n",
        "    if not path_list or len(path_list) < 2:\n",
        "        return None\n",
        "\n",
        "    dirs = []\n",
        "    for i in range(len(path_list) - 1):\n",
        "        r1, c1 = path_list[i]\n",
        "        r2, c2 = path_list[i+1]\n",
        "\n",
        "        if r2 > r1: dirs.append(\"d\")\n",
        "        elif r2 < r1: dirs.append(\"u\")\n",
        "        elif c2 > c1: dirs.append(\"r\")\n",
        "        elif c2 < c1: dirs.append(\"l\")\n",
        "\n",
        "    return \"\".join(dirs)\n",
        "\n",
        "def clean_image_id(filename):\n",
        "    \"\"\" '0001.png' -> 1 \"\"\"\n",
        "    s = str(filename).lower()\n",
        "    s = s.replace(\".png\", \"\").replace(\".jpg\", \"\")\n",
        "    try:\n",
        "        return int(s)\n",
        "    except:\n",
        "        return s\n",
        "\n",
        "# ==========================================\n",
        "# 5. SOLVER\n",
        "# ==========================================\n",
        "def solve_image(image_path):\n",
        "    # 1. Slice\n",
        "    grid_tensor, mask_tensor, status = extract_grid_data(image_path)\n",
        "    if \"Active\" not in status: return None\n",
        "\n",
        "    rows, cols = mask_tensor.shape\n",
        "    batch_tensors = []\n",
        "    coords = []\n",
        "\n",
        "    # 2. Batch\n",
        "    for r in range(rows):\n",
        "        for c in range(cols):\n",
        "            if mask_tensor[r, c] == 1:\n",
        "                rgb_cell = cv2.cvtColor(grid_tensor[r, c], cv2.COLOR_BGR2RGB)\n",
        "                batch_tensors.append(transform_pipe(rgb_cell))\n",
        "                coords.append((r, c))\n",
        "\n",
        "    if not batch_tensors: return None\n",
        "\n",
        "    # 3. Predict\n",
        "    batch_stack = torch.stack(batch_tensors).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(batch_stack)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "    # 4. Map\n",
        "    terrain_map = np.full((rows, cols), \"Unknown\", dtype=object)\n",
        "    counts = {\"Desert\": 0, \"Forest\": 0, \"Lab\": 0}\n",
        "\n",
        "    for i, (r, c) in enumerate(coords):\n",
        "        class_name = idx_to_class[preds[i].item()]\n",
        "        terrain_map[r, c] = class_name\n",
        "\n",
        "        biome = class_name.split(\"_\")[0] if \"_\" in class_name else \"Lab\"\n",
        "        weight = 3 if any(x in class_name for x in [\"Cacti\", \"Tree\", \"Plasma\", \"Wall\", \"Rocks\"]) else 1\n",
        "        if \"Start\" in class_name or \"End\" in class_name: weight = 5\n",
        "        counts[biome] = counts.get(biome, 0) + weight\n",
        "\n",
        "    dominant_biome = max(counts, key=counts.get) if counts else \"Lab\"\n",
        "    costs = COST_TABLES.get(dominant_biome, COST_TABLES[\"Lab\"])\n",
        "\n",
        "    # 5. A*\n",
        "    start_pos, end_pos = None, None\n",
        "    for r in range(rows):\n",
        "        for c in range(cols):\n",
        "            if \"Start\" in terrain_map[r, c]: start_pos = (r, c)\n",
        "            if \"End\" in terrain_map[r, c]: end_pos = (r, c)\n",
        "\n",
        "    if not start_pos or not end_pos: return None\n",
        "\n",
        "    pq = [(0, start_pos)]\n",
        "    cost_so_far = {start_pos: 0}\n",
        "    came_from = {}\n",
        "\n",
        "    while pq:\n",
        "        curr_cost, curr = heapq.heappop(pq)\n",
        "        if curr == end_pos:\n",
        "            path = []\n",
        "            while curr != start_pos:\n",
        "                path.append(curr)\n",
        "                curr = came_from[curr]\n",
        "            path.append(start_pos)\n",
        "            path.reverse()\n",
        "            return path_coords_to_string(path)\n",
        "\n",
        "        r, c = curr\n",
        "        for nr, nc in [(r-1,c), (r+1,c), (r,c-1), (r,c+1)]:\n",
        "            if 0 <= nr < rows and 0 <= nc < cols:\n",
        "                label = terrain_map[nr, nc]\n",
        "                cell_type = label.split(\"_\")[1] if \"_\" in label else label\n",
        "                step_cost = costs.get(cell_type, 999.0)\n",
        "\n",
        "                new_cost = cost_so_far[curr] + step_cost\n",
        "                if step_cost < 100:\n",
        "                    if (nr, nc) not in cost_so_far or new_cost < cost_so_far[(nr, nc)]:\n",
        "                        cost_so_far[(nr, nc)] = new_cost\n",
        "                        priority = new_cost + abs(nr-end_pos[0]) + abs(nc-end_pos[1])\n",
        "                        heapq.heappush(pq, (priority, (nr, nc)))\n",
        "                        came_from[(nr, nc)] = curr\n",
        "\n",
        "    return None\n",
        "\n",
        "# ==========================================\n",
        "# 6. RUN\n",
        "# ==========================================\n",
        "test_files = sorted(list(TEST_IMG_DIR.glob(\"*.png\")))\n",
        "data = []\n",
        "\n",
        "print(f\"Generating Submission for {len(test_files)} images...\")\n",
        "\n",
        "for img_path in tqdm(test_files):\n",
        "    path_str = solve_image(img_path)\n",
        "    data.append({\n",
        "        \"image_id\": clean_image_id(img_path.name),\n",
        "        \"path\": path_str\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df = df.sort_values(by=\"image_id\")\n",
        "df.to_csv(OUTPUT_CSV, index=False)\n",
        "print(f\"âœ… Submission saved to {OUTPUT_CSV}\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-22T13:09:54.457713Z",
          "iopub.status.busy": "2025-12-22T13:09:54.45696Z",
          "iopub.status.idle": "2025-12-22T13:09:54.593081Z",
          "shell.execute_reply": "2025-12-22T13:09:54.592383Z",
          "shell.execute_reply.started": "2025-12-22T13:09:54.457655Z"
        },
        "id": "LrqoQmNsoZGo",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "\n",
        "# ==========================================\n",
        "# CONFIGURATION\n",
        "# ==========================================\n",
        "MAIN_FILE   = \"submission.csv\"      # The V13 file you just generated\n",
        "BACKUP_FILE = \"/kaggle/input/subfill4/submission_filled(4).csv\"          # Your backup file (any format)\n",
        "OUTPUT_FILE = \"final_submission.csv\"\n",
        "\n",
        "# ==========================================\n",
        "# 1. HELPER FUNCTIONS\n",
        "# ==========================================\n",
        "def clean_id(val):\n",
        "    \"\"\" Converts '0001.png', '1.png', '0001' -> 1 \"\"\"\n",
        "    s = str(val).lower().strip()\n",
        "    s = s.replace(\".png\", \"\").replace(\".jpg\", \"\")\n",
        "    try:\n",
        "        return int(s)\n",
        "    except:\n",
        "        return None # Should not happen if data is clean\n",
        "\n",
        "def clean_path(val):\n",
        "    \"\"\" Converts Coords OR uppercase dirs to 'ldru' \"\"\"\n",
        "    if pd.isna(val) or val == \"\" or str(val).lower() == \"nan\":\n",
        "        return None\n",
        "\n",
        "    val = str(val).strip()\n",
        "\n",
        "    # CASE 1: Coordinate String like \"(0,0)->(0,1)\"\n",
        "    if \"->\" in val and \"(\" in val:\n",
        "        matches = re.findall(r\"\\((\\d+),(\\d+)\\)\", val)\n",
        "        path = [(int(r), int(c)) for r, c in matches]\n",
        "        dirs = []\n",
        "        for i in range(len(path) - 1):\n",
        "            r1, c1 = path[i]\n",
        "            r2, c2 = path[i+1]\n",
        "            if r2 > r1: dirs.append(\"d\")\n",
        "            elif r2 < r1: dirs.append(\"u\")\n",
        "            elif c2 > c1: dirs.append(\"r\")\n",
        "            elif c2 < c1: dirs.append(\"l\")\n",
        "        return \"\".join(dirs)\n",
        "\n",
        "    # CASE 2: Direction String like \"RRDD\" or \"rrdd\"\n",
        "    return val.lower()\n",
        "\n",
        "# ==========================================\n",
        "# 2. EXECUTION\n",
        "# ==========================================\n",
        "print(\"ðŸ”„ Loading files...\")\n",
        "\n",
        "# --- LOAD MAIN ---\n",
        "if not os.path.exists(MAIN_FILE):\n",
        "    print(f\"âŒ Error: {MAIN_FILE} not found. Generate it first!\")\n",
        "    exit()\n",
        "\n",
        "df_main = pd.read_csv(MAIN_FILE)\n",
        "# Standardize Columns\n",
        "if \"Image\" in df_main.columns: df_main.rename(columns={\"Image\": \"image_id\"}, inplace=True)\n",
        "if \"Path\" in df_main.columns: df_main.rename(columns={\"Path\": \"path\"}, inplace=True)\n",
        "\n",
        "# --- LOAD BACKUP ---\n",
        "if os.path.exists(BACKUP_FILE):\n",
        "    df_backup = pd.read_csv(BACKUP_FILE)\n",
        "    # Heuristic to find columns\n",
        "    cols = df_backup.columns\n",
        "    # Rename 1st col to image_id, 2nd to path (assuming standard structure)\n",
        "    df_backup.rename(columns={cols[0]: \"image_id\", cols[1]: \"path\"}, inplace=True)\n",
        "    print(f\"âœ… Backup loaded ({len(df_backup)} rows)\")\n",
        "else:\n",
        "    print(\"âš ï¸  Backup file not found. Creating empty backup.\")\n",
        "    df_backup = pd.DataFrame(columns=[\"image_id\", \"path\"])\n",
        "\n",
        "# ==========================================\n",
        "# 3. STANDARDIZATION\n",
        "# ==========================================\n",
        "print(\"ðŸ”§ Standardizing IDs and Paths...\")\n",
        "\n",
        "# Clean IDs to Integer\n",
        "df_main['clean_id'] = df_main['image_id'].apply(clean_id)\n",
        "df_backup['clean_id'] = df_backup['image_id'].apply(clean_id)\n",
        "\n",
        "# Clean Paths to 'ldru'\n",
        "df_main['clean_path'] = df_main['path'].apply(clean_path)\n",
        "df_backup['clean_path'] = df_backup['path'].apply(clean_path)\n",
        "\n",
        "# ==========================================\n",
        "# 4. MERGE & FILL\n",
        "# ==========================================\n",
        "print(\"ðŸ©¹ Merging and patching holes...\")\n",
        "\n",
        "# Merge on the clean Integer ID\n",
        "df_final = df_main.merge(df_backup[['clean_id', 'clean_path']],\n",
        "                         on='clean_id',\n",
        "                         how='left',\n",
        "                         suffixes=('', '_backup'))\n",
        "\n",
        "# Logic: Use Main Path. If None, use Backup Path.\n",
        "def fill_strategy(row):\n",
        "    main_p = row['clean_path']\n",
        "    back_p = row['clean_path_backup']\n",
        "\n",
        "    if main_p is not None and len(main_p) > 0:\n",
        "        return main_p\n",
        "    return back_p\n",
        "\n",
        "df_final['final_path'] = df_final.apply(fill_strategy, axis=1)\n",
        "\n",
        "# ==========================================\n",
        "# 5. OUTPUT FORMATTING\n",
        "# ==========================================\n",
        "# Select only required columns\n",
        "output_df = df_final[['clean_id', 'final_path']].copy()\n",
        "output_df.columns = ['image_id', 'path']\n",
        "\n",
        "# Sort by ID\n",
        "output_df = output_df.sort_values(by=\"image_id\")\n",
        "\n",
        "# Check for remaining nulls\n",
        "missing = output_df['path'].isna().sum()\n",
        "if missing > 0:\n",
        "    print(f\"âš ï¸  Warning: {missing} paths are still empty (missing in both main and backup).\")\n",
        "else:\n",
        "    print(\"âœ… All paths filled successfully.\")\n",
        "\n",
        "# Save\n",
        "output_df.to_csv(OUTPUT_FILE, index=False)\n",
        "print(f\"ðŸš€ Saved Final Submission to: {OUTPUT_FILE}\")\n",
        "print(output_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoCMi4SBoZGp",
        "trusted": true
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "notebook9a94a897ca",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "databundleVersionId": 14910697,
          "sourceId": 125981,
          "sourceType": "competition"
        },
        {
          "datasetId": 9095930,
          "sourceId": 14255535,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 9066772,
          "sourceId": 14214076,
          "sourceType": "datasetVersion"
        },
        {
          "isSourceIdPinned": true,
          "modelId": 541284,
          "modelInstanceId": 527243,
          "sourceId": 695213,
          "sourceType": "modelInstanceVersion"
        }
      ],
      "dockerImageVersionId": 31236,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
