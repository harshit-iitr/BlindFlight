{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 125981,
          "databundleVersionId": 14910697,
          "sourceType": "competition"
        },
        {
          "sourceId": 683928,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 518957,
          "modelId": 533451
        },
        {
          "sourceId": 687677,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 521496,
          "modelId": 535676
        }
      ],
      "dockerImageVersionId": 31192,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "mN22zIARlDYh"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "the_blind_flight_synapse_drive_ps_1_path = kagglehub.competition_download('the-blind-flight-synapse-drive-ps-1')\n",
        "haragr10_blindflightunet_pytorch_default_1_path = kagglehub.model_download('haragr10/blindflightunet/PyTorch/default/1')\n",
        "haragr10_blindflightfinal_pytorch_2_1_path = kagglehub.model_download('haragr10/blindflightfinal/PyTorch/2/1')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "U0p6P_3klDYk"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample Pipeline:\n",
        "  - Load small training set (20 maps) from:\n",
        "\n",
        "        train/images/*.png\n",
        "\n",
        "        train/labels/*.json     # contains true class grid\n",
        "\n",
        "        train/velocities/*.json # boost; we ignore it in this baseline\n",
        "\n",
        "  - Train a tiny NN that predicts a 20x20 class grid from the image.\n",
        "\n",
        "        * It treats all terrains together (no terrain-specific modeling).\n",
        "\n",
        "        * It only uses per-cell average colour (super crude).\n",
        "\n",
        "  - For each test image:\n",
        "\n",
        "        * Predict class grid.\n",
        "\n",
        "        * Find start (class 3) and goal (class 4).\n",
        "\n",
        "        * Compute a path with a dumb cost model (ignoring boosts).\n",
        "\n",
        "        * Convert path to an 'lrud' sequence and write submission_baseline.csv\n",
        "        "
      ],
      "metadata": {
        "id": "tfpDLe2XlDYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install albumentations --no-deps\n",
        "!pip install \"numpy<2\"\n",
        "!pip install -U segmentation-models-pytorch"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-16T09:58:01.030655Z",
          "iopub.execute_input": "2025-12-16T09:58:01.030957Z",
          "iopub.status.idle": "2025-12-16T09:59:23.571074Z",
          "shell.execute_reply.started": "2025-12-16T09:58:01.030933Z",
          "shell.execute_reply": "2025-12-16T09:59:23.570155Z"
        },
        "id": "o5jOVjr-lDYm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random, numpy as np, cv2, torch, torch.nn as nn, torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from PIL import Image, ImageDraw\n",
        "import segmentation_models_pytorch as smp\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ---------------- CONFIG ----------------\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "GRID_SIZE = 20\n",
        "TILE_SIZE = 40\n",
        "IMG_SIZE = 800\n",
        "BATCH_SIZE = 16\n",
        "ACCUM_STEPS = 4\n",
        "\n",
        "# ---------------- ASSETS ----------------\n",
        "INPUT_ROOT = Path(\"/kaggle/input\")\n",
        "ASSET_ROOT = next((p for p in INPUT_ROOT.rglob(\"assets\") if p.is_dir()), Path(\"assets\"))\n",
        "\n",
        "def load_asset(path):\n",
        "    try:\n",
        "        return Image.open(path).convert(\"RGBA\").resize((TILE_SIZE, TILE_SIZE))\n",
        "    except:\n",
        "        return Image.new(\"RGBA\", (TILE_SIZE, TILE_SIZE), (128,128,128,255))\n",
        "\n",
        "ASSETS = {\n",
        "    0: {\"floor\":[load_asset(ASSET_ROOT/\"lab/t2_floor.png\")],\n",
        "        \"wall\":[load_asset(ASSET_ROOT/\"lab/t2_wall.png\")],\n",
        "        \"hazard\":[load_asset(ASSET_ROOT/\"lab/t2_glue.png\")],\n",
        "        \"start\":load_asset(ASSET_ROOT/\"lab/t2_drone.png\"),\n",
        "        \"goal\":load_asset(ASSET_ROOT/\"lab/t2_goal.png\")},\n",
        "    1: {\"floor\":[load_asset(ASSET_ROOT/\"forest/t0_dirt.png\")],\n",
        "        \"wall\":[load_asset(ASSET_ROOT/\"forest/t0_tree.png\")],\n",
        "        \"hazard\":[load_asset(ASSET_ROOT/\"forest/t0_puddle.png\")],\n",
        "        \"start\":load_asset(ASSET_ROOT/\"forest/t0_startship.png\"),\n",
        "        \"goal\":load_asset(ASSET_ROOT/\"forest/t0_goal.png\")},\n",
        "    2: {\"floor\":[load_asset(ASSET_ROOT/\"desert/t1_sand.png\")],\n",
        "        \"wall\":[load_asset(ASSET_ROOT/\"desert/t1_rocks.png\")],\n",
        "        \"hazard\":[load_asset(ASSET_ROOT/\"desert/t1_quicksand.png\")],\n",
        "        \"start\":load_asset(ASSET_ROOT/\"desert/t1_rover.png\"),\n",
        "        \"goal\":load_asset(ASSET_ROOT/\"desert/t1_goal.png\")}\n",
        "}\n",
        "\n",
        "# ---------------- DATASET ----------------\n",
        "class StableSkewDataset(Dataset):\n",
        "    def __init__(self, length=10000):\n",
        "        self.length = length\n",
        "        self.color = A.Compose([\n",
        "            A.HueSaturationValue(5, 10, 5, p=0.4),\n",
        "            A.RGBShift(10, 10, 10, p=0.3),\n",
        "            A.RandomBrightnessContrast(0.1, 0.1, p=0.4),\n",
        "        ])\n",
        "        self.blur = A.OneOf([\n",
        "            A.GaussianBlur((3, 5), p=1.0),\n",
        "            A.MotionBlur((3, 7), p=1.0)\n",
        "        ], p=0.4)\n",
        "        self.final = A.Compose([\n",
        "            A.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "            ToTensorV2()\n",
        "        ])\n",
        "\n",
        "    def __len__(self): return self.length\n",
        "\n",
        "    def mild_skew(self, img, mask):\n",
        "        if random.random() > 0.4: return img, mask\n",
        "        h, w = img.shape[:2]\n",
        "        limit = 18\n",
        "        pts1 = np.float32([[0, 0], [w, 0], [0, h], [w, h]])\n",
        "        pts2 = np.float32([\n",
        "            [random.randint(0, limit), random.randint(0, limit)],\n",
        "            [w - random.randint(0, limit), random.randint(0, limit)],\n",
        "            [random.randint(0, limit), h - random.randint(0, limit)],\n",
        "            [w - random.randint(0, limit), h - random.randint(0, limit)]\n",
        "        ])\n",
        "        M = cv2.getPerspectiveTransform(pts1, pts2)\n",
        "        img = cv2.warpPerspective(img, M, (w, h), borderMode=cv2.BORDER_REFLECT_101)\n",
        "        mask = cv2.warpPerspective(mask, M, (w, h), flags=cv2.INTER_NEAREST, borderMode=cv2.BORDER_REFLECT_101)\n",
        "        return img, mask\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        t_id = random.choice([0, 1, 2])\n",
        "        assets = ASSETS[t_id]\n",
        "        grid = np.random.choice([0, 1, 2], (GRID_SIZE, GRID_SIZE), p=[0.7, 0.2, 0.1])\n",
        "        s, g = random.sample([(r, c) for r in range(GRID_SIZE) for c in range(GRID_SIZE)], 2)\n",
        "        grid[s] = 3; grid[g] = 4\n",
        "\n",
        "        # Grid Rotation\n",
        "        k = random.choice([0, 1, 2, 3])\n",
        "        if k > 0: grid = np.rot90(grid, k=k)\n",
        "\n",
        "        canvas = Image.new(\"RGBA\", (IMG_SIZE, IMG_SIZE), (0, 0, 0, 255))\n",
        "        draw = ImageDraw.Draw(canvas)\n",
        "\n",
        "        for r in range(GRID_SIZE):\n",
        "            for c in range(GRID_SIZE):\n",
        "                x, y = c * TILE_SIZE, r * TILE_SIZE\n",
        "                canvas.paste(random.choice(assets[\"floor\"]), (x, y))\n",
        "                cell = grid[r, c]\n",
        "                if cell == 1: canvas.paste(random.choice(assets[\"wall\"]), (x, y))\n",
        "                elif cell == 2: canvas.paste(random.choice(assets[\"hazard\"]), (x, y))\n",
        "                elif cell == 3: canvas.paste(assets[\"start\"], (x, y))\n",
        "                elif cell == 4: canvas.paste(assets[\"goal\"], (x, y))\n",
        "\n",
        "                # Black Border\n",
        "                draw.rectangle([x, y, x + TILE_SIZE - 1, y + TILE_SIZE - 1], outline=(0, 0, 0), width=2)\n",
        "\n",
        "        img = np.array(canvas.convert(\"RGB\"))\n",
        "        mask_full = cv2.resize(grid.astype(np.uint8), (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)\n",
        "        img, mask_full = self.mild_skew(img, mask_full)\n",
        "\n",
        "        img = self.color(image=img)[\"image\"]\n",
        "        img = self.blur(image=img)[\"image\"]\n",
        "        img = self.final(image=img)[\"image\"]\n",
        "\n",
        "        mask = cv2.resize(mask_full, (GRID_SIZE, GRID_SIZE), interpolation=cv2.INTER_NEAREST)\n",
        "        return img, torch.from_numpy(mask).long(), torch.tensor(t_id).long()\n",
        "\n",
        "# ---------------- MODEL ----------------\n",
        "class MultiHeadUNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.unet = smp.Unet(encoder_name=\"resnet34\", encoder_weights=\"imagenet\", in_channels=3, classes=5)\n",
        "        c = self.unet.encoder.out_channels[-1]\n",
        "        self.terrain = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1), nn.Flatten(),\n",
        "            nn.Linear(c,64), nn.ReLU(), nn.Linear(64,3)\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        feats = self.unet.encoder(x)\n",
        "        terr = self.terrain(feats[-1])\n",
        "        dec = self.unet.decoder(feats)\n",
        "        seg = self.unet.segmentation_head(dec)\n",
        "        seg = torch.nn.functional.interpolate(seg,(GRID_SIZE,GRID_SIZE), mode=\"bilinear\",align_corners=False)\n",
        "        return seg, terr\n",
        "\n",
        "# ---------------- COUNT LOSS ----------------\n",
        "class CountConsistencyLoss(nn.Module):\n",
        "    def forward(self, logits):\n",
        "        probs = torch.softmax(logits,1)\n",
        "        return sum(((probs[:,c].sum((1,2))-1)**2).mean() for c in [3,4])\n",
        "\n",
        "# ---------------- TRAIN ----------------\n",
        "def train():\n",
        "    dl = DataLoader(StableSkewDataset(), BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
        "    model = MultiHeadUNet().to(DEVICE)\n",
        "    if torch.cuda.device_count() > 1: model = nn.DataParallel(model)\n",
        "\n",
        "    opt = optim.AdamW(model.parameters(), 1e-3, weight_decay=1e-2)\n",
        "    scaler = GradScaler()\n",
        "    sched = optim.lr_scheduler.ReduceLROnPlateau(opt, \"min\", 0.5, 2)\n",
        "\n",
        "    # FIX: Use floats (1.0, 5.0) to prevent Scalar Type Error\n",
        "    ce = nn.CrossEntropyLoss(weight=torch.tensor([1.0, 5.0, 5.0, 50.0, 50.0], device=DEVICE))\n",
        "    terr_ce = nn.CrossEntropyLoss()\n",
        "    count_loss = CountConsistencyLoss()\n",
        "\n",
        "    print(\"ðŸš€ Starting Training... (Press SQUARE STOP BUTTON to save & exit early)\")\n",
        "\n",
        "    try:\n",
        "        for ep in range(15):\n",
        "            model.train()\n",
        "            loop = tqdm(dl, desc=f\"Epoch {ep+1}/15\")\n",
        "            epoch_loss = 0\n",
        "\n",
        "            for i, (x, y, t) in enumerate(loop):\n",
        "                x, y, t = x.to(DEVICE), y.to(DEVICE), t.to(DEVICE)\n",
        "\n",
        "                with autocast():\n",
        "                    seg, terr = model(x)\n",
        "\n",
        "                    l_seg = ce(seg, y)\n",
        "                    l_terr = 0.5 * terr_ce(terr, t)\n",
        "\n",
        "                    l_count = torch.tensor(0.0, device=DEVICE)\n",
        "                    if ep >= 5:\n",
        "                        l_count = 0.2 * count_loss(seg)\n",
        "\n",
        "                    loss = (l_seg + l_terr + l_count) / ACCUM_STEPS\n",
        "\n",
        "                scaler.scale(loss).backward()\n",
        "\n",
        "                if (i+1) % ACCUM_STEPS == 0:\n",
        "                    scaler.step(opt); scaler.update(); opt.zero_grad()\n",
        "                    epoch_loss += loss.item() * ACCUM_STEPS\n",
        "\n",
        "                    # Update Progress Bar with ALL losses\n",
        "                    loop.set_postfix({\n",
        "                        \"Seg\": f\"{l_seg.item():.3f}\",\n",
        "                        \"Terr\": f\"{l_terr.item():.3f}\",\n",
        "                        \"Cnt\": f\"{l_count.item():.3f}\",\n",
        "                        \"Tot\": f\"{loss.item()*ACCUM_STEPS:.3f}\"\n",
        "                    })\n",
        "\n",
        "            sched.step(epoch_loss/len(dl))\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nðŸ›‘ Training Interrupted by User! Saving current state...\")\n",
        "\n",
        "    # Save logic runs even if interrupted\n",
        "    torch.save(model.module.state_dict() if isinstance(model, nn.DataParallel) else model.state_dict(),\n",
        "               \"unet_stable_skew_final.pth\")\n",
        "    print(\"âœ… Model Saved: unet_stable_skew_final.pth\")\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    train()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-16T10:59:38.89136Z",
          "iopub.execute_input": "2025-12-16T10:59:38.892066Z",
          "iopub.status.idle": "2025-12-16T12:39:02.16309Z",
          "shell.execute_reply.started": "2025-12-16T10:59:38.892034Z",
          "shell.execute_reply": "2025-12-16T12:39:02.162286Z"
        },
        "id": "vwI4iw6UlDYn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "import albumentations as A\n",
        "from PIL import Image, ImageDraw, ImageEnhance\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# --- CONFIG ---\n",
        "GRID_SIZE = 20\n",
        "TILE_SIZE = 40\n",
        "IMG_SIZE = 800\n",
        "INPUT_ROOT = Path(\"/kaggle/input\")\n",
        "TEST_IMG_DIR = Path(\"/kaggle/input/the-blind-flight-synapse-drive-ps-1/SynapseDrive_Dataset/test/images\")\n",
        "\n",
        "# --- 1. ASSETS ---\n",
        "ASSET_ROOT = None\n",
        "for path in INPUT_ROOT.rglob(\"assets\"):\n",
        "    if path.is_dir():\n",
        "        ASSET_ROOT = path\n",
        "        break\n",
        "if not ASSET_ROOT: ASSET_ROOT = Path(\"assets\")\n",
        "\n",
        "def load_asset(path):\n",
        "    try:\n",
        "        return Image.open(path).convert(\"RGBA\").resize((TILE_SIZE, TILE_SIZE))\n",
        "    except FileNotFoundError:\n",
        "        return Image.new(\"RGBA\", (TILE_SIZE, TILE_SIZE), (128, 128, 128, 255))\n",
        "\n",
        "ASSETS = {\n",
        "    0: {\"floor\": [load_asset(ASSET_ROOT/\"lab/t2_floor.png\")], \"wall\": [load_asset(ASSET_ROOT/\"lab/t2_wall.png\")], \"hazard\": [load_asset(ASSET_ROOT/\"lab/t2_glue.png\")], \"start\": load_asset(ASSET_ROOT/\"lab/t2_drone.png\"), \"goal\": load_asset(ASSET_ROOT/\"lab/t2_goal.png\")},\n",
        "    1: {\"floor\": [load_asset(ASSET_ROOT/\"forest/t0_dirt.png\")], \"wall\": [load_asset(ASSET_ROOT/\"forest/t0_tree.png\")], \"hazard\": [load_asset(ASSET_ROOT/\"forest/t0_puddle.png\")], \"start\": load_asset(ASSET_ROOT/\"forest/t0_startship.png\"), \"goal\": load_asset(ASSET_ROOT/\"forest/t0_goal.png\")},\n",
        "    2: {\"floor\": [load_asset(ASSET_ROOT/\"desert/t1_sand.png\")], \"wall\": [load_asset(ASSET_ROOT/\"desert/t1_rocks.png\")], \"hazard\": [load_asset(ASSET_ROOT/\"desert/t1_quicksand.png\")], \"start\": load_asset(ASSET_ROOT/\"desert/t1_rover.png\"), \"goal\": load_asset(ASSET_ROOT/\"desert/t1_goal.png\")}\n",
        "}\n",
        "\n",
        "# --- 2. REFINED DATASET CLASS ---\n",
        "class RefinedSkewDataset(Dataset):\n",
        "    def __init__(self, length=20):\n",
        "        self.length = length\n",
        "\n",
        "        # A. Global Transforms (Rotation + Tint)\n",
        "        self.global_transform = A.Compose([\n",
        "            A.RandomRotate90(p=0.5), # Added explicit rotation augmentation\n",
        "            A.HueSaturationValue(hue_shift_limit=5, sat_shift_limit=10, val_shift_limit=5, p=0.4),\n",
        "            A.RGBShift(r_shift_limit=10, g_shift_limit=10, b_shift_limit=10, p=0.3),\n",
        "            A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.4),\n",
        "        ])\n",
        "\n",
        "        # B. Blur (High Probability)\n",
        "        self.blur_transform = A.OneOf([\n",
        "            A.GaussianBlur(blur_limit=(3, 7), p=0.8),\n",
        "            A.MotionBlur(blur_limit=(3, 9), p=0.8),\n",
        "        ], p=0.8) # Increased to 80% to ensure it appears often\n",
        "\n",
        "    def apply_tint_patches(self, image_np):\n",
        "        \"\"\"\n",
        "        Creates localized circles (radius ~3 tiles) with SUBTLE color shifts.\n",
        "        \"\"\"\n",
        "        h_img, w_img, _ = image_np.shape\n",
        "        mask = np.zeros((h_img, w_img), dtype=np.uint8)\n",
        "\n",
        "        num_patches = random.randint(0, 3)\n",
        "        if num_patches == 0: return image_np\n",
        "\n",
        "        for _ in range(num_patches):\n",
        "            radius = random.randint(100, 140)\n",
        "            cx, cy = random.randint(0, w_img), random.randint(0, h_img)\n",
        "            cv2.circle(mask, (cx, cy), radius, 255, -1)\n",
        "\n",
        "        img_hsv = cv2.cvtColor(image_np, cv2.COLOR_RGB2HSV).astype(np.int32)\n",
        "\n",
        "        # --- REDUCED INTENSITY HERE ---\n",
        "        # Hue +/- 10 (was 20), Sat +20 (was 40)\n",
        "        h_shift = random.randint(-10, 10)\n",
        "        s_shift = random.randint(0, 20)\n",
        "        v_shift = random.randint(-10, 10)\n",
        "\n",
        "        img_hsv[:, :, 0] = (img_hsv[:, :, 0] + h_shift) % 180\n",
        "        img_hsv[:, :, 1] = np.clip(img_hsv[:, :, 1] + s_shift, 0, 255)\n",
        "        img_hsv[:, :, 2] = np.clip(img_hsv[:, :, 2] + v_shift, 0, 255)\n",
        "\n",
        "        img_tinted = cv2.cvtColor(img_hsv.astype(np.uint8), cv2.COLOR_HSV2RGB)\n",
        "\n",
        "        mask_bool = mask > 0\n",
        "        image_np[mask_bool] = img_tinted[mask_bool]\n",
        "\n",
        "        return image_np\n",
        "\n",
        "    def __len__(self): return self.length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # 1. Base Grid Generation\n",
        "        t_id = random.choice([0, 1, 2])\n",
        "        assets = ASSETS[t_id]\n",
        "        grid_label = np.random.choice([0, 1, 2], size=(GRID_SIZE, GRID_SIZE), p=[0.7, 0.2, 0.1])\n",
        "        p1, p2 = random.sample([(r, c) for r in range(GRID_SIZE) for c in range(GRID_SIZE)], 2)\n",
        "        grid_label[p1] = 3; grid_label[p2] = 4\n",
        "\n",
        "        # Grid Rotation (Structural)\n",
        "        grid_label = np.rot90(grid_label, k=random.choice([0, 1, 2, 3]))\n",
        "\n",
        "        full_w, full_h = GRID_SIZE * TILE_SIZE, GRID_SIZE * TILE_SIZE\n",
        "        canvas = Image.new(\"RGBA\", (full_w, full_h), (0, 0, 0, 255))\n",
        "        draw = ImageDraw.Draw(canvas)\n",
        "\n",
        "        for r in range(GRID_SIZE):\n",
        "            for c in range(GRID_SIZE):\n",
        "                x, y = c * TILE_SIZE, r * TILE_SIZE\n",
        "                cell = grid_label[r, c]\n",
        "                canvas.paste(random.choice(assets[\"floor\"]), (x, y))\n",
        "                if cell == 1: canvas.paste(random.choice(assets[\"wall\"]), (x, y))\n",
        "                elif cell == 2: canvas.paste(random.choice(assets[\"hazard\"]) if assets.get(\"hazard\") else assets[\"wall\"][0], (x, y))\n",
        "                elif cell == 3: canvas.paste(assets[\"start\"], (x, y))\n",
        "                elif cell == 4: canvas.paste(assets[\"goal\"], (x, y))\n",
        "\n",
        "                # DRAW BLACK BORDER\n",
        "                draw.rectangle([x, y, x + TILE_SIZE - 1, y + TILE_SIZE - 1], outline=(0, 0, 0, 255), width=2)\n",
        "\n",
        "        image_np = np.array(canvas.convert(\"RGB\"))\n",
        "\n",
        "        # 2. Apply Local Color Patches\n",
        "        image_np = self.apply_tint_patches(image_np)\n",
        "\n",
        "        # 3. Geometric Skew (Increased Severity + Frequency)\n",
        "        if random.random() < 0.8: # Fixed probability (was mismatch in comments)\n",
        "            pts1 = np.float32([[0,0], [full_w,0], [0,full_h], [full_w,full_h]])\n",
        "\n",
        "            # INCREASED Skew Limit to 55 (was 40)\n",
        "            limit = 55\n",
        "            tl = [random.randint(0, limit), random.randint(0, limit)]\n",
        "            tr = [full_w - random.randint(0, limit), random.randint(0, limit)]\n",
        "            bl = [random.randint(0, limit), full_h - random.randint(0, limit)]\n",
        "            br = [full_w - random.randint(0, limit), full_h - random.randint(0, limit)]\n",
        "\n",
        "            pts2 = np.float32([tl, tr, bl, br])\n",
        "            M = cv2.getPerspectiveTransform(pts1, pts2)\n",
        "\n",
        "            image_np = cv2.warpPerspective(image_np, M, (full_w, full_h), borderValue=(0,0,0))\n",
        "\n",
        "            # Apply Global Augmentations (Blur, Rotate, etc.)\n",
        "            image_np = self.global_transform(image=image_np)['image']\n",
        "            image_np = self.blur_transform(image=image_np)['image']\n",
        "\n",
        "        return image_np\n",
        "\n",
        "# --- 3. DISPLAY FUNCTION ---\n",
        "def show_training_data_preview():\n",
        "    train_dataset = RefinedSkewDataset(length=20)\n",
        "\n",
        "    try:\n",
        "        test_files = list(TEST_IMG_DIR.glob(\"*.png\"))\n",
        "        if len(test_files) < 10: test_files = []\n",
        "    except Exception:\n",
        "        test_files = []\n",
        "\n",
        "    rows = 10\n",
        "    fig, axes = plt.subplots(rows, 2, figsize=(14, 4 * rows))\n",
        "    plt.subplots_adjust(wspace=0.1, hspace=0.2)\n",
        "\n",
        "    print(\"ðŸŽ¨ Previewing Data Generation...\")\n",
        "    print(\"LEFT: Synthetic Training Data (Subtle Patch + Strong Skew + Blur)\")\n",
        "    print(\"RIGHT: Real Test Data (If available)\")\n",
        "\n",
        "    for i in range(rows):\n",
        "        img_train = train_dataset[i]\n",
        "        axes[i, 0].imshow(img_train)\n",
        "        axes[i, 0].set_title(f\"TRAIN: Skew+Blur+Patch\", fontsize=10, color='green')\n",
        "        axes[i, 0].axis('off')\n",
        "\n",
        "        if test_files:\n",
        "            img_path = random.choice(test_files)\n",
        "            img_test = Image.open(img_path).convert(\"RGB\")\n",
        "            axes[i, 1].imshow(img_test)\n",
        "            axes[i, 1].set_title(f\"TEST: {img_path.name}\", fontsize=10, color='blue')\n",
        "            axes[i, 1].axis('off')\n",
        "        else:\n",
        "            axes[i, 1].axis('off')\n",
        "            axes[i, 1].text(0.5, 0.5, \"No Test Data Found\", ha='center')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    show_training_data_preview()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-16T10:21:14.668871Z",
          "iopub.execute_input": "2025-12-16T10:21:14.669424Z",
          "iopub.status.idle": "2025-12-16T10:21:21.167824Z",
          "shell.execute_reply.started": "2025-12-16T10:21:14.6694Z",
          "shell.execute_reply": "2025-12-16T10:21:21.166328Z"
        },
        "id": "XkS9Ui4WlDYo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import numpy as np\n",
        "import torch\n",
        "import cv2\n",
        "import json\n",
        "import heapq\n",
        "import random\n",
        "import albumentations as A\n",
        "import torch.nn as nn\n",
        "import segmentation_models_pytorch as smp\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Ensure this matches the name of the file you saved\n",
        "MODEL_PATH = \"unet_stable_skew_final.pth\"\n",
        "TEST_IMG_DIR = Path(\"/kaggle/input/the-blind-flight-synapse-drive-ps-1/SynapseDrive_Dataset/test/images\")\n",
        "TEST_VEL_DIR = Path(\"/kaggle/input/the-blind-flight-synapse-drive-ps-1/SynapseDrive_Dataset/test/velocities\")\n",
        "\n",
        "# --- PHYSICS CONSTANTS ---\n",
        "TERRAIN_CONFIG = {\n",
        "    0: {\n",
        "        \"name\": \"LAB\",\n",
        "        \"costs\": {0: 1.0, 1: float('inf'), 2: 3.0, 3: 1.0, 4: 2.0}\n",
        "    },\n",
        "    1: {\n",
        "        \"name\": \"FOREST\",\n",
        "        \"costs\": {0: 1.5, 1: float('inf'), 2: 2.8, 3: 1.5, 4: 2.5}\n",
        "    },\n",
        "    2: {\n",
        "        \"name\": \"DESERT\",\n",
        "        \"costs\": {0: 1.2, 1: float('inf'), 2: 3.7, 3: 1.2, 4: 2.2}\n",
        "    }\n",
        "}\n",
        "\n",
        "# --- MODEL DEFINITION (Must Match Training Script) ---\n",
        "class MultiHeadUNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Matches the training parameters\n",
        "        self.unet = smp.Unet(encoder_name=\"resnet34\", encoder_weights=None,\n",
        "                             in_channels=3, classes=5)\n",
        "\n",
        "        # Matches the 'self.terrain' head from training\n",
        "        c = self.unet.encoder.out_channels[-1]\n",
        "        self.terrain = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(c, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 3)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.unet.encoder(x)\n",
        "        # Use the same head name as training\n",
        "        terrain_logits = self.terrain(features[-1])\n",
        "\n",
        "        decoder_out = self.unet.decoder(features)\n",
        "        seg_logits = self.unet.segmentation_head(decoder_out)\n",
        "\n",
        "        # Interpolate to 20x20 during inference for planning\n",
        "        seg_logits = torch.nn.functional.interpolate(\n",
        "            seg_logits, size=(20, 20),\n",
        "            mode='bilinear', align_corners=False\n",
        "        )\n",
        "        return seg_logits, terrain_logits\n",
        "\n",
        "# --- PATH PLANNER ---\n",
        "class StarkPathPlanner:\n",
        "    def __init__(self, grid_classes, boost_matrix, terrain_id):\n",
        "        self.grid = grid_classes\n",
        "        self.boost = boost_matrix\n",
        "        self.costs = TERRAIN_CONFIG[terrain_id][\"costs\"]\n",
        "        self.rows, self.cols = grid_classes.shape\n",
        "\n",
        "    def heuristic(self, a, b):\n",
        "        # Manhattan distance\n",
        "        return abs(a[0] - b[0]) + abs(a[1] - b[1])\n",
        "\n",
        "    def solve(self, start, end):\n",
        "        pq = [(0, start)]\n",
        "        g_scores = {start: 0.0}\n",
        "        came_from = {}\n",
        "\n",
        "        while pq:\n",
        "            _, current = heapq.heappop(pq)\n",
        "            if current == end:\n",
        "                return self.reconstruct_path(came_from, current)\n",
        "\n",
        "            r, c = current\n",
        "            # Neighbors: Up, Down, Left, Right\n",
        "            neighbors = [((r-1, c), 'u'), ((r+1, c), 'd'),\n",
        "                         ((r, c-1), 'l'), ((r, c+1), 'r')]\n",
        "\n",
        "            for next_cell, move_dir in neighbors:\n",
        "                nr, nc = next_cell\n",
        "\n",
        "                # Bounds check\n",
        "                if not (0 <= nr < self.rows and 0 <= nc < self.cols): continue\n",
        "\n",
        "                # Wall check (Class 1 is Wall)\n",
        "                if self.grid[nr, nc] == 1: continue\n",
        "\n",
        "                # Cost Calculation: Base Cost - Boost\n",
        "                cell_type = self.grid[nr, nc]\n",
        "                base = self.costs.get(cell_type, 1.0)\n",
        "\n",
        "                # Boost logic: subtract boost from cost, minimum cost 0.01\n",
        "                boost_val = self.boost[nr, nc]\n",
        "                cost = max(base - boost_val, 0.01)\n",
        "\n",
        "                new_g = g_scores[current] + cost\n",
        "\n",
        "                if new_g < g_scores.get(next_cell, float('inf')):\n",
        "                    g_scores[next_cell] = new_g\n",
        "                    came_from[next_cell] = (current, move_dir)\n",
        "                    priority = new_g + self.heuristic(next_cell, end)\n",
        "                    heapq.heappush(pq, (priority, next_cell))\n",
        "\n",
        "        return None, []\n",
        "\n",
        "    def reconstruct_path(self, came_from, current):\n",
        "        path_str = []\n",
        "        path_coords = [current]\n",
        "        while current in came_from:\n",
        "            prev, move = came_from[current]\n",
        "            path_str.append(move)\n",
        "            path_coords.append(prev)\n",
        "            current = prev\n",
        "        return \"\".join(path_str[::-1]), path_coords[::-1]\n",
        "\n",
        "# --- VISUALIZER ---\n",
        "def visualize_check(num_samples=3):\n",
        "    # Load Model\n",
        "    model = MultiHeadUNet().to(DEVICE)\n",
        "    try:\n",
        "        model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
        "        print(\"âœ… Model loaded successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Failed to load model: {e}\")\n",
        "        return\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    transform = A.Compose([\n",
        "        A.Resize(800, 800),\n",
        "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "    # Grab Test Files\n",
        "    try:\n",
        "        files = list(TEST_IMG_DIR.glob(\"*.png\"))\n",
        "        if not files:\n",
        "            print(\"Warning: No test images found. Using dummy data?\")\n",
        "            return\n",
        "        samples = random.sample(files, min(len(files), num_samples))\n",
        "    except Exception as e:\n",
        "        print(f\"Error accessing test directory: {e}\")\n",
        "        return\n",
        "\n",
        "    for img_path in samples:\n",
        "        # 1. Inference\n",
        "        original_image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
        "        t_img = transform(image=original_image)['image'].unsqueeze(0).to(DEVICE)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            seg, terr = model(t_img)\n",
        "            # Seg is already 20x20 due to model definition above\n",
        "            grid = torch.argmax(seg, dim=1).squeeze().cpu().numpy()\n",
        "            t_id = torch.argmax(terr, dim=1).item()\n",
        "\n",
        "        # 2. Load Velocity (if available)\n",
        "        boost = np.zeros((20, 20))\n",
        "        json_path = TEST_VEL_DIR / f\"{img_path.stem}.json\"\n",
        "        if json_path.exists():\n",
        "            try:\n",
        "                with open(json_path) as f:\n",
        "                    boost = np.array(json.load(f)['boost'])\n",
        "            except:\n",
        "                pass # Default to zero boost if error\n",
        "\n",
        "        # 3. Plan Path\n",
        "        # Find Start (3) and Goal (4)\n",
        "        starts = np.argwhere(grid == 3)\n",
        "        goals = np.argwhere(grid == 4)\n",
        "\n",
        "        path_str = \"NO PATH\"\n",
        "        path_coords = []\n",
        "\n",
        "        if len(starts) > 0 and len(goals) > 0:\n",
        "            # Take the first found start/goal if duplicates exist\n",
        "            start_node = tuple(starts[0])\n",
        "            goal_node = tuple(goals[0])\n",
        "\n",
        "            planner = StarkPathPlanner(grid, boost, t_id)\n",
        "            path_str, path_coords = planner.solve(start_node, goal_node)\n",
        "            if not path_str: path_str = \"NO PATH\"\n",
        "\n",
        "        # 4. Plotting\n",
        "        fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "        # Left: Image + Path\n",
        "        ax[0].imshow(original_image)\n",
        "        t_name = TERRAIN_CONFIG.get(t_id, {}).get(\"name\", \"UNKNOWN\")\n",
        "        ax[0].set_title(f\"Terrain: {t_name} | Path: {path_str[:20]}...\")\n",
        "\n",
        "        if path_coords:\n",
        "            # Scale 20x20 coordinates to 800x800 image space for plotting\n",
        "            scale_y = original_image.shape[0] / 20\n",
        "            scale_x = original_image.shape[1] / 20\n",
        "\n",
        "            # Extract Y and X coordinates\n",
        "            py, px = zip(*path_coords)\n",
        "\n",
        "            # Shift by 0.5 to center on tile and scale up\n",
        "            plot_x = [(x + 0.5) * scale_x for x in px]\n",
        "            plot_y = [(y + 0.5) * scale_y for y in py]\n",
        "\n",
        "            ax[0].plot(plot_x, plot_y, 'r-', linewidth=4, label=\"Path\", alpha=0.8)\n",
        "            ax[0].scatter(plot_x[0], plot_y[0], c='lime', s=100, label='Start', zorder=5)\n",
        "            ax[0].scatter(plot_x[-1], plot_y[-1], c='magenta', s=100, label='Goal', zorder=5)\n",
        "            ax[0].legend()\n",
        "        else:\n",
        "            ax[0].text(400, 400, \"NO PATH FOUND\", color='red', fontsize=20,\n",
        "                       ha='center', va='center', backgroundcolor='black')\n",
        "\n",
        "        # Right: Predicted Grid\n",
        "        # Custom color map for clarity: Floor, Wall, Haz, Start, Goal\n",
        "        cmap = plt.get_cmap('tab10', 5)\n",
        "        im = ax[1].imshow(grid, cmap=cmap, vmin=-0.5, vmax=4.5)\n",
        "        ax[1].set_title(\"Predicted Segmentation Grid (20x20)\")\n",
        "\n",
        "        # Add legend for grid\n",
        "        cbar = plt.colorbar(im, ax=ax[1], ticks=[0, 1, 2, 3, 4])\n",
        "        cbar.ax.set_yticklabels(['Floor', 'Wall', 'Hazard', 'Start', 'Goal'])\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# RUN IT\n",
        "if __name__ == \"__main__\":\n",
        "    visualize_check(30)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-16T13:04:36.332661Z",
          "iopub.execute_input": "2025-12-16T13:04:36.332998Z",
          "iopub.status.idle": "2025-12-16T13:05:04.148514Z",
          "shell.execute_reply.started": "2025-12-16T13:04:36.332975Z",
          "shell.execute_reply": "2025-12-16T13:05:04.147748Z"
        },
        "id": "RZ3GbCOZlDYq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import segmentation_models_pytorch as smp\n",
        "import json\n",
        "import heapq\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# --- 1. CONFIGURATION ---\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Ensure this matches your saved file name\n",
        "MODEL_PATH = \"unet_stable_skew_final.pth\"\n",
        "TEST_IMG_DIR = Path(\"/kaggle/input/the-blind-flight-synapse-drive-ps-1/SynapseDrive_Dataset/test/images\")\n",
        "TEST_VEL_DIR = Path(\"/kaggle/input/the-blind-flight-synapse-drive-ps-1/SynapseDrive_Dataset/test/velocities\")\n",
        "BATCH_SIZE = 64  # High throughput\n",
        "NUM_WORKERS = 4\n",
        "\n",
        "# --- 2. PHYSICS CONSTANTS ---\n",
        "TERRAIN_CONFIG = {\n",
        "    0: {\"name\": \"LAB\", \"costs\": {0: 1.0, 1: float('inf'), 2: 3.0, 3: 1.0, 4: 2.0}},\n",
        "    1: {\"name\": \"FOREST\", \"costs\": {0: 1.5, 1: float('inf'), 2: 2.8, 3: 1.5, 4: 2.5}},\n",
        "    2: {\"name\": \"DESERT\", \"costs\": {0: 1.2, 1: float('inf'), 2: 3.7, 3: 1.2, 4: 2.2}}\n",
        "}\n",
        "\n",
        "# --- 3. MODEL DEFINITION (Must Match Training) ---\n",
        "class MultiHeadUNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Matches the training parameters\n",
        "        self.unet = smp.Unet(encoder_name=\"resnet34\", encoder_weights=None,\n",
        "                             in_channels=3, classes=5)\n",
        "\n",
        "        # Matches the 'self.terrain' head from training\n",
        "        c = self.unet.encoder.out_channels[-1]\n",
        "        self.terrain = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(c, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 3)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.unet.encoder(x)\n",
        "        # Use the same head name as training\n",
        "        terrain_logits = self.terrain(features[-1])\n",
        "\n",
        "        decoder_out = self.unet.decoder(features)\n",
        "        seg_logits = self.unet.segmentation_head(decoder_out)\n",
        "\n",
        "        # Interpolate to 20x20 during inference for planning\n",
        "        seg_logits = torch.nn.functional.interpolate(\n",
        "            seg_logits, size=(20, 20),\n",
        "            mode='bilinear', align_corners=False\n",
        "        )\n",
        "        return seg_logits, terrain_logits\n",
        "\n",
        "# --- 4. DATASET ---\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, img_dir, vel_dir):\n",
        "        self.img_paths = sorted(list(img_dir.glob(\"*.png\")))\n",
        "        self.vel_dir = vel_dir\n",
        "        self.transform = A.Compose([\n",
        "            A.Resize(800, 800),\n",
        "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "            ToTensorV2(),\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        image_id = img_path.stem\n",
        "\n",
        "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
        "        t_img = self.transform(image=image)['image']\n",
        "\n",
        "        v_path = self.vel_dir / f\"{image_id}.json\"\n",
        "        if v_path.exists():\n",
        "            with open(v_path, 'r') as f:\n",
        "                boost = np.array(json.load(f)['boost'], dtype=np.float32)\n",
        "        else:\n",
        "            boost = np.zeros((20, 20), dtype=np.float32)\n",
        "\n",
        "        return t_img, boost, image_id\n",
        "\n",
        "# --- 5. OPTIMIZED DIJKSTRA PLANNER ---\n",
        "class StarkPathPlanner:\n",
        "    def __init__(self, grid_classes, boost_matrix, terrain_id):\n",
        "        self.grid = grid_classes\n",
        "        self.boost = boost_matrix\n",
        "        self.costs = TERRAIN_CONFIG[terrain_id][\"costs\"]\n",
        "        self.rows, self.cols = grid_classes.shape\n",
        "\n",
        "    def solve(self, start, end):\n",
        "        # Priority Queue: (Cost, Current_Cell)\n",
        "        # Note: No Heuristic here. Just pure cost accumulation.\n",
        "        pq = [(0, start)]\n",
        "\n",
        "        # Track minimum cost to reach each cell\n",
        "        min_costs = {start: 0.0}\n",
        "        came_from = {}\n",
        "\n",
        "        while pq:\n",
        "            current_cost, current = heapq.heappop(pq)\n",
        "\n",
        "            # Optimization: If we found a path to 'current' that is cheaper already, skip\n",
        "            if current_cost > min_costs.get(current, float('inf')):\n",
        "                continue\n",
        "\n",
        "            if current == end:\n",
        "                return self.reconstruct_path(came_from, current)\n",
        "\n",
        "            r, c = current\n",
        "            neighbors = [((r-1, c), 'u'), ((r+1, c), 'd'), ((r, c-1), 'l'), ((r, c+1), 'r')]\n",
        "\n",
        "            for next_cell, move_dir in neighbors:\n",
        "                nr, nc = next_cell\n",
        "\n",
        "                # Bounds check\n",
        "                if not (0 <= nr < self.rows and 0 <= nc < self.cols):\n",
        "                    continue\n",
        "\n",
        "                # Wall check\n",
        "                if self.grid[nr, nc] == 1:\n",
        "                    continue\n",
        "\n",
        "                # PHYSICS ENGINE: Cost = Base - Boost\n",
        "                base = self.costs.get(self.grid[nr, nc], 1.0)\n",
        "\n",
        "                # Floor cost at 0.01 to prevent infinite loops or negative weights\n",
        "                # Dijkstra requires non-negative edge weights!\n",
        "                step_cost = max(base - self.boost[nr, nc], 0.01)\n",
        "\n",
        "                new_cost = current_cost + step_cost\n",
        "\n",
        "                # If this path is cheaper than any previous path to this neighbor\n",
        "                if new_cost < min_costs.get(next_cell, float('inf')):\n",
        "                    min_costs[next_cell] = new_cost\n",
        "                    came_from[next_cell] = (current, move_dir)\n",
        "                    heapq.heappush(pq, (new_cost, next_cell))\n",
        "\n",
        "        return None\n",
        "\n",
        "    def reconstruct_path(self, came_from, current):\n",
        "        path = []\n",
        "        while current in came_from:\n",
        "            prev, move = came_from[current]\n",
        "            path.append(move)\n",
        "            current = prev\n",
        "        return \"\".join(path[::-1])\n",
        "\n",
        "# --- 6. MAIN EXECUTION ---\n",
        "def generate_submission():\n",
        "    print(f\"â³ Loading Model from {MODEL_PATH}...\")\n",
        "\n",
        "    # Load Weights (CPU safe first)\n",
        "    if not Path(MODEL_PATH).exists():\n",
        "        print(f\"âŒ Error: Model file '{MODEL_PATH}' not found!\")\n",
        "        return\n",
        "\n",
        "    checkpoint = torch.load(MODEL_PATH, map_location=\"cpu\")\n",
        "    model = MultiHeadUNet()\n",
        "\n",
        "    # Fix DataParallel keys if present (e.g. 'module.unet...')\n",
        "    if list(checkpoint.keys())[0].startswith('module.'):\n",
        "        checkpoint = {k[7:]: v for k, v in checkpoint.items()}\n",
        "\n",
        "    try:\n",
        "        model.load_state_dict(checkpoint)\n",
        "        print(\"âœ… Weights loaded successfully.\")\n",
        "    except RuntimeError as e:\n",
        "        print(f\"âŒ Weight mismatch! Check class definition.\\n{e}\")\n",
        "        return\n",
        "\n",
        "    if torch.cuda.device_count() > 1:\n",
        "        print(f\"ðŸ”¥ Dual-GPU Activated: {torch.cuda.device_count()} GPUs\")\n",
        "        model = nn.DataParallel(model)\n",
        "\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "\n",
        "    # Dataset & Loader\n",
        "    # Check if directories exist\n",
        "    if not TEST_IMG_DIR.exists():\n",
        "        print(\"âŒ Test Image Directory not found. Check path.\")\n",
        "        return\n",
        "\n",
        "    test_ds = TestDataset(TEST_IMG_DIR, TEST_VEL_DIR)\n",
        "    loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "    results = []\n",
        "    print(f\"ðŸš€ Starting Dijkstra Inference on {len(test_ds)} images...\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_imgs, batch_boosts, batch_ids in tqdm(loader, desc=\"Planning\"):\n",
        "            batch_imgs = batch_imgs.to(DEVICE)\n",
        "\n",
        "            # 1. Model Inference\n",
        "            seg_logits, terrain_logits = model(batch_imgs)\n",
        "\n",
        "            # 2. Resize is already done inside forward() -> (20x20)\n",
        "\n",
        "            # 3. CPU Transfer\n",
        "            grids = torch.argmax(seg_logits, dim=1).cpu().numpy()\n",
        "            t_ids = torch.argmax(terrain_logits, dim=1).cpu().numpy()\n",
        "            boosts = batch_boosts.numpy()\n",
        "\n",
        "            # 4. Dijkstra Loop (CPU)\n",
        "            for i in range(len(batch_ids)):\n",
        "                image_id = batch_ids[i]\n",
        "                grid = grids[i]\n",
        "                t_id = t_ids[i].item()\n",
        "                boost = boosts[i]\n",
        "\n",
        "                path_str = \"\"\n",
        "                starts = np.argwhere(grid == 3)\n",
        "                goals = np.argwhere(grid == 4)\n",
        "\n",
        "                if len(starts) > 0 and len(goals) > 0:\n",
        "                    planner = StarkPathPlanner(grid, boost, t_id)\n",
        "                    # Solves for global optimum now\n",
        "                    res = planner.solve(tuple(starts[0]), tuple(goals[0]))\n",
        "                    if res: path_str = res\n",
        "\n",
        "                results.append({\"image_id\": image_id, \"path\": path_str})\n",
        "\n",
        "    # Save\n",
        "    df = pd.DataFrame(results)\n",
        "    df.to_csv(\"submission.csv\", index=False)\n",
        "    print(f\"âœ… Submission saved with {len(df)} rows.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    generate_submission()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-16T13:09:07.34656Z",
          "iopub.execute_input": "2025-12-16T13:09:07.347047Z"
        },
        "id": "Zzf6bqCElDYr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the dataframe\n",
        "df = pd.read_csv('/kaggle/working/submission.csv')\n",
        "\n",
        "# Inspect the dataframe\n",
        "\n",
        "# Fill missing values with 'd'\n",
        "df_filled = df.fillna('d')\n",
        "\n",
        "# Verify the changes\n",
        "print(df_filled.info())\n",
        "print(df_filled[df['path'].isna()].head()) # Check rows that were originally missing\n",
        "\n",
        "# Save the modified dataframe to a new CSV\n",
        "df_filled.to_csv('submission_filled.csv', index=False)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-14T18:04:05.908696Z",
          "iopub.execute_input": "2025-12-14T18:04:05.909172Z",
          "iopub.status.idle": "2025-12-14T18:04:05.944954Z",
          "shell.execute_reply.started": "2025-12-14T18:04:05.909145Z",
          "shell.execute_reply": "2025-12-14T18:04:05.94435Z"
        },
        "id": "4FtRk1GXlDYt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "qmQrBekKlDYu"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}